{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Assignment 1, classification task**\n",
    "### Ostapovich Oleg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functions import *\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#loading data\n",
    "stream_quality_df = pd.read_csv('stream_quality_data/train_data.csv')\n",
    "stream_quality_test = pd.read_csv('stream_quality_data/test_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   fps_mean   fps_std  fps_lags  rtt_mean    rtt_std  dropped_frames_mean  \\\n0      24.4  0.516398         0      91.1   6.723921                  0.0   \n1      28.6  2.065591         0      99.7  15.923777                  0.0   \n2      30.0  0.000000         0      98.1  11.798776                  0.0   \n3      30.3  0.948683         0      99.4  13.014522                  0.0   \n4      29.9  0.316228         0     123.2  62.476307                  0.0   \n\n   dropped_frames_std  dropped_frames_max auto_bitrate_state auto_fec_state  \\\n0                 0.0                 0.0                off        partial   \n1                 0.0                 0.0                off        partial   \n2                 0.0                 0.0                off        partial   \n3                 0.0                 0.0                off        partial   \n4                 0.0                 0.0                off        partial   \n\n   auto_fec_mean  stream_quality  \n0           50.0               0  \n1           50.0               0  \n2           50.0               0  \n3           50.0               0  \n4           50.0               0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fps_mean</th>\n      <th>fps_std</th>\n      <th>fps_lags</th>\n      <th>rtt_mean</th>\n      <th>rtt_std</th>\n      <th>dropped_frames_mean</th>\n      <th>dropped_frames_std</th>\n      <th>dropped_frames_max</th>\n      <th>auto_bitrate_state</th>\n      <th>auto_fec_state</th>\n      <th>auto_fec_mean</th>\n      <th>stream_quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24.4</td>\n      <td>0.516398</td>\n      <td>0</td>\n      <td>91.1</td>\n      <td>6.723921</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>off</td>\n      <td>partial</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28.6</td>\n      <td>2.065591</td>\n      <td>0</td>\n      <td>99.7</td>\n      <td>15.923777</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>off</td>\n      <td>partial</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>98.1</td>\n      <td>11.798776</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>off</td>\n      <td>partial</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30.3</td>\n      <td>0.948683</td>\n      <td>0</td>\n      <td>99.4</td>\n      <td>13.014522</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>off</td>\n      <td>partial</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.9</td>\n      <td>0.316228</td>\n      <td>0</td>\n      <td>123.2</td>\n      <td>62.476307</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>off</td>\n      <td>partial</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_quality_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Data preprocessing at labels\n",
    "stream_quality_df, stream_quality_test = LabelEncoderforClassification(stream_quality_df,stream_quality_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   fps_mean   fps_std  fps_lags  rtt_mean    rtt_std  dropped_frames_mean  \\\n0      24.4  0.516398         0      91.1   6.723921                  0.0   \n1      28.6  2.065591         0      99.7  15.923777                  0.0   \n2      30.0  0.000000         0      98.1  11.798776                  0.0   \n3      30.3  0.948683         0      99.4  13.014522                  0.0   \n4      29.9  0.316228         0     123.2  62.476307                  0.0   \n\n   dropped_frames_std  dropped_frames_max  auto_bitrate_state  auto_fec_state  \\\n0                 0.0                 0.0                   1               1   \n1                 0.0                 0.0                   1               1   \n2                 0.0                 0.0                   1               1   \n3                 0.0                 0.0                   1               1   \n4                 0.0                 0.0                   1               1   \n\n   auto_fec_mean  stream_quality  \n0           50.0               0  \n1           50.0               0  \n2           50.0               0  \n3           50.0               0  \n4           50.0               0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fps_mean</th>\n      <th>fps_std</th>\n      <th>fps_lags</th>\n      <th>rtt_mean</th>\n      <th>rtt_std</th>\n      <th>dropped_frames_mean</th>\n      <th>dropped_frames_std</th>\n      <th>dropped_frames_max</th>\n      <th>auto_bitrate_state</th>\n      <th>auto_fec_state</th>\n      <th>auto_fec_mean</th>\n      <th>stream_quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24.4</td>\n      <td>0.516398</td>\n      <td>0</td>\n      <td>91.1</td>\n      <td>6.723921</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28.6</td>\n      <td>2.065591</td>\n      <td>0</td>\n      <td>99.7</td>\n      <td>15.923777</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>98.1</td>\n      <td>11.798776</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30.3</td>\n      <td>0.948683</td>\n      <td>0</td>\n      <td>99.4</td>\n      <td>13.014522</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.9</td>\n      <td>0.316228</td>\n      <td>0</td>\n      <td>123.2</td>\n      <td>62.476307</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_quality_df.head() #here what happened with data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Data preprocessing at numerical data\n",
    "stream_quality_df, stream_quality_test = NumericalEncoderforClassification(stream_quality_df,stream_quality_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   fps_mean   fps_std  fps_lags  rtt_mean   rtt_std  dropped_frames_mean  \\\n0  0.191975  0.001652       0.0  0.007063  0.000165                  0.0   \n1  0.225020  0.006609       0.0  0.007730  0.000391                  0.0   \n2  0.236035  0.000000       0.0  0.007606  0.000290                  0.0   \n3  0.238395  0.003035       0.0  0.007706  0.000320                  0.0   \n4  0.235248  0.001012       0.0  0.009552  0.001534                  0.0   \n\n   dropped_frames_std  dropped_frames_max  auto_bitrate_state  auto_fec_state  \\\n0                 0.0                 0.0                   1               1   \n1                 0.0                 0.0                   1               1   \n2                 0.0                 0.0                   1               1   \n3                 0.0                 0.0                   1               1   \n4                 0.0                 0.0                   1               1   \n\n   auto_fec_mean  stream_quality  \n0            0.2               0  \n1            0.2               0  \n2            0.2               0  \n3            0.2               0  \n4            0.2               0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fps_mean</th>\n      <th>fps_std</th>\n      <th>fps_lags</th>\n      <th>rtt_mean</th>\n      <th>rtt_std</th>\n      <th>dropped_frames_mean</th>\n      <th>dropped_frames_std</th>\n      <th>dropped_frames_max</th>\n      <th>auto_bitrate_state</th>\n      <th>auto_fec_state</th>\n      <th>auto_fec_mean</th>\n      <th>stream_quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.191975</td>\n      <td>0.001652</td>\n      <td>0.0</td>\n      <td>0.007063</td>\n      <td>0.000165</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.225020</td>\n      <td>0.006609</td>\n      <td>0.0</td>\n      <td>0.007730</td>\n      <td>0.000391</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.236035</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.007606</td>\n      <td>0.000290</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.238395</td>\n      <td>0.003035</td>\n      <td>0.0</td>\n      <td>0.007706</td>\n      <td>0.000320</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.235248</td>\n      <td>0.001012</td>\n      <td>0.0</td>\n      <td>0.009552</td>\n      <td>0.001534</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_quality_df.head() #here what happened with data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Samples :  (406572, 12)\n",
      "Number of Outliers :  (36759, 12)\n",
      "Number of Normal Samples :  (369813, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iforest = IsolationForest()\n",
    "X = stream_quality_df.iloc[:, :8]\n",
    "iforest.fit(X)\n",
    "pred = iforest.predict(X)\n",
    "outliers = stream_quality_df[pred == -1]\n",
    "stream_quality_df_valid = stream_quality_df[pred != -1]\n",
    "\n",
    "print(\"Original Samples : \",stream_quality_df.shape)\n",
    "print(\"Number of Outliers : \", outliers.shape)\n",
    "print(\"Number of Normal Samples : \", stream_quality_df_valid.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_train_df = stream_quality_df_valid['stream_quality']\n",
    "x_train_df = stream_quality_df_valid.drop(['stream_quality'], axis=1)\n",
    "\n",
    "y_test = stream_quality_test['stream_quality']\n",
    "x_test = stream_quality_test.drop(['stream_quality'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (369813, 11)\n",
      "X_train resampled shape: (710236, 11)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_df,y_train_df)\n",
    "print('X_train shape:', x_train_df.shape)\n",
    "print('X_train resampled shape:', x_train_resampled.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before split (369813, 11) (369813,) (243596, 11) (243596,)\n",
      "after split (568188, 11) (568188,) (142048, 11) (142048,) (243596, 11) (243596,)\n"
     ]
    }
   ],
   "source": [
    "print(\"before split\", x_train_df.shape, y_train_df.shape, x_test.shape, y_test.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_resampled, y_train_resampled, train_size=0.8)\n",
    "print(\"after split\", x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Dset(Dataset):\n",
    "    def __init__(self, values, labels):\n",
    "        self.x = torch.tensor(values.values, dtype= torch.float32)\n",
    "        # self.y = torch.from_numpy(labels.values).type(torch.LongTensor)\n",
    "        self.y = list(map(int, labels.values))\n",
    "    def __len__(self):\n",
    "        return (len(self.y))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# Adding data to loader\n",
    "trainloader = torch.utils.data.DataLoader(Dset(x_train,y_train), batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0\n",
    "                                          )\n",
    "valloader = torch.utils.data.DataLoader(Dset(x_val,y_val), batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                        num_workers=0\n",
    "                                        )\n",
    "testloader = torch.utils.data.DataLoader(Dset(x_test,y_test), batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                         num_workers=0\n",
    "                                         )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def train_evaluate(net, optimizer, writer, epochs):\n",
    "    starttime = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.NLLLoss()\n",
    "    accuracy_func = Accuracy(num_classes=3, average='weighted').to(device)\n",
    "    f1_score_func = F1Score(num_classes=3, average='weighted').to(device)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        f1 = 0\n",
    "        accuracy = 0\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            accuracy += accuracy_func(pred, labels) * 100\n",
    "            f1 += f1_score_func(pred, labels) * 100\n",
    "\n",
    "        running_loss /= len(trainloader)\n",
    "        accuracy /= len(trainloader)\n",
    "        f1 /= len(trainloader)\n",
    "        writer.add_scalar('Training_Loss', running_loss, epoch)\n",
    "        writer.add_scalar('Training_Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Training_F1', f1, epoch)\n",
    "\n",
    "        print('Epoch {} - train loss:{}, accuracy:{}, f1_score:{}, time passed {}s'.format(epoch+1, running_loss, accuracy, f1, int(time.time()-starttime)))\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0\n",
    "        val_f1_score = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += accuracy_func(pred, labels) * 100\n",
    "                val_f1_score += f1_score_func(pred, labels) * 100\n",
    "            val_loss /= len(valloader)\n",
    "            val_accuracy /= len(valloader)\n",
    "            val_f1_score /= len(valloader)\n",
    "            writer.add_scalar('Val_Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val_Accuracy', val_accuracy, epoch)\n",
    "            writer.add_scalar('Val_F1', val_f1_score, epoch)\n",
    "\n",
    "        print('Epoch {} - val loss:{}, accuracy:{}, f1_score:{}, time passed {}s'.format(epoch+1, val_loss, val_accuracy, val_f1_score, int(time.time()-starttime)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def test_evaluate(net, optimizer):\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0\n",
    "    val_f1_score = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_func = Accuracy(num_classes=3, average='weighted').to(device)\n",
    "    f1_score_func = F1Score(num_classes=3, average='weighted').to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += accuracy_func(pred, labels) * 100\n",
    "            val_f1_score += f1_score_func(pred, labels) * 100\n",
    "        val_loss /= len(testloader)\n",
    "        val_accuracy /= len(testloader)\n",
    "        val_f1_score /= len(testloader)\n",
    "    print('Test evaluation - test loss:{}, accuracy:{}, f1_score:{}'.format(val_loss, val_accuracy, val_f1_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class StartModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StartModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Linear(in_features=11, out_features=3, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "startmodel = StartModel().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:0.6608105957487107, accuracy:61.020938873291016, f1_score:60.53476333618164, time passed 58s\n",
      "Epoch 1 - val loss:0.6611437576493271, accuracy:61.373268127441406, f1_score:61.25039291381836, time passed 70s\n",
      "Epoch 2 - train loss:0.6598881250093286, accuracy:61.08101272583008, f1_score:60.627647399902344, time passed 131s\n",
      "Epoch 2 - val loss:0.660210203025477, accuracy:60.94633865356445, f1_score:60.3121452331543, time passed 143s\n",
      "Epoch 3 - train loss:0.6591256231394758, accuracy:61.200199127197266, f1_score:60.757232666015625, time passed 199s\n",
      "Epoch 3 - val loss:0.6595481897977605, accuracy:61.32676696777344, f1_score:61.132022857666016, time passed 212s\n",
      "Epoch 4 - train loss:0.6585220160072264, accuracy:61.281028747558594, f1_score:60.8638916015625, time passed 268s\n",
      "Epoch 4 - val loss:0.6589222196791056, accuracy:61.349693298339844, f1_score:61.1363410949707, time passed 281s\n",
      "Epoch 5 - train loss:0.6580171445774722, accuracy:61.29631042480469, f1_score:60.880577087402344, time passed 337s\n",
      "Epoch 5 - val loss:0.6585714128720433, accuracy:61.4322624206543, f1_score:61.264732360839844, time passed 349s\n",
      "Epoch 6 - train loss:0.6576201815875388, accuracy:61.391746520996094, f1_score:60.9793815612793, time passed 405s\n",
      "Epoch 6 - val loss:0.6580703253061481, accuracy:61.20941925048828, f1_score:60.766685485839844, time passed 418s\n",
      "Epoch 7 - train loss:0.6572917140063078, accuracy:61.37517166137695, f1_score:60.96217727661133, time passed 474s\n",
      "Epoch 7 - val loss:0.657892744571369, accuracy:61.3994255065918, f1_score:60.61382293701172, time passed 486s\n",
      "Epoch 8 - train loss:0.6570023517296458, accuracy:61.47328186035156, f1_score:61.04133605957031, time passed 542s\n",
      "Epoch 8 - val loss:0.6575758787714873, accuracy:61.41766357421875, f1_score:61.02607345581055, time passed 555s\n",
      "Epoch 9 - train loss:0.656798383439355, accuracy:61.53284454345703, f1_score:61.11161804199219, time passed 610s\n",
      "Epoch 9 - val loss:0.657338554258501, accuracy:61.55271911621094, f1_score:61.33279800415039, time passed 623s\n",
      "Epoch 10 - train loss:0.6565820083195204, accuracy:61.49797821044922, f1_score:61.06629180908203, time passed 678s\n",
      "Epoch 10 - val loss:0.6584085780998756, accuracy:60.621917724609375, f1_score:59.082923889160156, time passed 691s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [26], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdadelta(startmodel\u001B[38;5;241m.\u001B[39mparameters())\n\u001B[0;32m      2\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mruns1/BaseModelbase2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstartmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [21], line 24\u001B[0m, in \u001B[0;36mtrain_evaluate\u001B[1;34m(net, optimizer, writer, epochs)\u001B[0m\n\u001B[0;32m     22\u001B[0m     _, pred \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m     accuracy \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m accuracy_func(pred, labels) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m---> 24\u001B[0m     f1 \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mf1_score_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m     26\u001B[0m running_loss \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainloader)\n\u001B[0;32m     27\u001B[0m accuracy \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainloader)\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\metric.py:245\u001B[0m, in \u001B[0;36mMetric.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_full_state_update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    244\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 245\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_reduce_state_update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\metric.py:309\u001B[0m, in \u001B[0;36mMetric._forward_reduce_state_update\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# allow grads for batch computation\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# calculate batch state and compute batch value\u001B[39;00m\n\u001B[1;32m--> 309\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    310\u001B[0m batch_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute()\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# reduce batch and global state\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\metric.py:395\u001B[0m, in \u001B[0;36mMetric._wrap_update.<locals>.wrapped_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad):\n\u001B[0;32m    394\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 395\u001B[0m         update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    397\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected all tensors to be on\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:706\u001B[0m, in \u001B[0;36mStatScores.update\u001B[1;34m(self, preds, target)\u001B[0m\n\u001B[0;32m    697\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate\u001B[39m(\u001B[38;5;28mself\u001B[39m, preds: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m    698\u001B[0m     \u001B[38;5;124;03m\"\"\"Update state with predictions and targets.\u001B[39;00m\n\u001B[0;32m    699\u001B[0m \n\u001B[0;32m    700\u001B[0m \u001B[38;5;124;03m    See :ref:`pages/classification:input types` for more information on input types.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;124;03m        target: Ground truth values\u001B[39;00m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 706\u001B[0m     tp, fp, tn, fn \u001B[38;5;241m=\u001B[39m \u001B[43m_stat_scores_update\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    707\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    708\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    710\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmdmc_reduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmdmc_reduce\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    711\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    712\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtop_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulticlass\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulticlass\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    718\u001B[0m     \u001B[38;5;66;03m# Update states\u001B[39;00m\n\u001B[0;32m    719\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduce \u001B[38;5;241m!=\u001B[39m AverageMethod\u001B[38;5;241m.\u001B[39mSAMPLES \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmdmc_reduce \u001B[38;5;241m!=\u001B[39m MDMCAverageMethod\u001B[38;5;241m.\u001B[39mSAMPLEWISE:\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:954\u001B[0m, in \u001B[0;36m_stat_scores_update\u001B[1;34m(preds, target, reduce, mdmc_reduce, num_classes, top_k, threshold, multiclass, ignore_index, mode)\u001B[0m\n\u001B[0;32m    951\u001B[0m     preds, target \u001B[38;5;241m=\u001B[39m _drop_negative_ignored_indices(preds, target, ignore_index, mode)\n\u001B[0;32m    952\u001B[0m     _negative_index_dropped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 954\u001B[0m preds, target, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_input_format_classification\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    956\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmulticlass\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulticlass\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m ignore_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m preds\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `ignore_index` \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mignore_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not valid for inputs with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpreds\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m classes\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:412\u001B[0m, in \u001B[0;36m_input_format_classification\u001B[1;34m(preds, target, threshold, top_k, num_classes, multiclass, ignore_index)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat16:\n\u001B[0;32m    410\u001B[0m     preds \u001B[38;5;241m=\u001B[39m preds\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m--> 412\u001B[0m case \u001B[38;5;241m=\u001B[39m \u001B[43m_check_classification_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmulticlass\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulticlass\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m case \u001B[38;5;129;01min\u001B[39;00m (DataType\u001B[38;5;241m.\u001B[39mBINARY, DataType\u001B[38;5;241m.\u001B[39mMULTILABEL) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m top_k:\n\u001B[0;32m    423\u001B[0m     preds \u001B[38;5;241m=\u001B[39m (preds \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m threshold)\u001B[38;5;241m.\u001B[39mint()\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:292\u001B[0m, in \u001B[0;36m_check_classification_inputs\u001B[1;34m(preds, target, threshold, num_classes, multiclass, top_k, ignore_index)\u001B[0m\n\u001B[0;32m    290\u001B[0m     _check_num_classes_binary(num_classes, multiclass)\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m case \u001B[38;5;129;01min\u001B[39;00m (DataType\u001B[38;5;241m.\u001B[39mMULTICLASS, DataType\u001B[38;5;241m.\u001B[39mMULTIDIM_MULTICLASS):\n\u001B[1;32m--> 292\u001B[0m     \u001B[43m_check_num_classes_mc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulticlass\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimplied_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m case\u001B[38;5;241m.\u001B[39mMULTILABEL:\n\u001B[0;32m    294\u001B[0m     _check_num_classes_ml(num_classes, multiclass, implied_classes)\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torchmetrics\\utilities\\checks.py:170\u001B[0m, in \u001B[0;36m_check_num_classes_mc\u001B[1;34m(preds, target, num_classes, multiclass, implied_classes)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m multiclass \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m implied_classes \u001B[38;5;241m!=\u001B[39m num_classes:\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    164\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have set `multiclass=False`, but the implied number of classes \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (from shape of inputs) does not match `num_classes`. If you are trying to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    168\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m See Input Types in Metrics documentation.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    169\u001B[0m     )\n\u001B[1;32m--> 170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mnum_classes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    171\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe highest label in `target` should be smaller than `num_classes`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m target\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;129;01mand\u001B[39;00m num_classes \u001B[38;5;241m!=\u001B[39m implied_classes:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adadelta(startmodel.parameters())\n",
    "writer = SummaryWriter('runs1/BaseModelbase2')\n",
    "train_evaluate(startmodel, optimizer, writer, 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Visualizing data with PCA\n",
    "dim_reducer = PCA(n_components=2)\n",
    "reduced_df = dim_reducer.fit_transform(stream_quality_df)\n",
    "plt.scatter(reduced_df[:, 0], reduced_df[:, 1], marker='.')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Splitting data to X and Y\n",
    "Y_train = stream_quality_df['stream_quality']\n",
    "X_train = stream_quality_df.drop(['stream_quality'], axis=1)\n",
    "\n",
    "Y_test = stream_quality_test['stream_quality']\n",
    "X_test = stream_quality_test.drop(['stream_quality'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection with Lasso"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on testset: 0.06029186327204236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1).fit(X_train,Y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "print(\"MSE on testset:\", mean_squared_error(Y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification task"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset 0.9367969917404226\n",
      "Precision on testset 0.5249247239879559\n",
      "Recall on testset 0.1999490251051357\n",
      "\n",
      "Accuracy on trainset 0.9447748492271971\n",
      "Precision on trainset 0.8499154636493692\n",
      "Recall on trainset 0.23478479557375873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(penalty='l2').fit(X_train,Y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "y_pred_train = logistic.predict(X_train)\n",
    "print('Accuracy on testset', accuracy_score(Y_test, y_pred))\n",
    "print('Precision on testset', precision_score(Y_test, y_pred))\n",
    "print('Recall on testset', recall_score(Y_test,y_pred))\n",
    "print('\\nAccuracy on trainset', accuracy_score(Y_train, y_pred_train))\n",
    "print('Precision on trainset', precision_score(Y_train, y_pred_train))\n",
    "print('Recall on trainset', recall_score(Y_train,y_pred_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset 0.9393627153155224\n",
      "Precision on testset 0.6274509803921569\n",
      "Recall on testset 0.14476870141455334\n",
      "\n",
      "Accuracy on trainset 0.9436434383085899\n",
      "Precision on trainset 0.9247367512515104\n",
      "Recall on trainset 0.1924624559890781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge = RidgeClassifier().fit(X_train,Y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "print('Accuracy on testset', accuracy_score(Y_test, y_pred))\n",
    "print('Precision on testset', precision_score(Y_test, y_pred))\n",
    "print('Recall on testset', recall_score(Y_test,y_pred))\n",
    "print('\\nAccuracy on trainset', accuracy_score(Y_train, y_pred_train))\n",
    "print('Precision on trainset', precision_score(Y_train, y_pred_train))\n",
    "print('Recall on trainset', recall_score(Y_train,y_pred_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RidgeClassifier and LogisticRegression give us similar results. Models work well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso cross validation score: [-0.00545202 -0.00371694 -0.0120003 ]\n",
      "Logistic Regression cross validation score: [0.93998695 0.9407505  0.93874233]\n",
      "Ridge Classifier cross validation score: [0.93938349 0.93977758 0.9385576 ]\n"
     ]
    }
   ],
   "source": [
    "#Let's see the results of cross validation score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Lasso cross validation score:', cross_val_score(lasso, X_test,Y_test, cv=3))\n",
    "print('Logistic Regression cross validation score:', cross_val_score(logistic, X_test,Y_test, cv=3))\n",
    "print('Ridge Classifier cross validation score:', cross_val_score(ridge, X_test,Y_test, cv=3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removal of outliers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#loading data\n",
    "stream_quality_df = pd.read_csv('stream_quality_data/train_data.csv')\n",
    "stream_quality_test = pd.read_csv('stream_quality_data/test_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "stream_quality_df, stream_quality_test = LabelEncoderforClassification(stream_quality_df,stream_quality_test)\n",
    "stream_quality_df, stream_quality_test = NumericalEncoderforClassification(stream_quality_df, stream_quality_test)\n",
    "Y_train = stream_quality_df['stream_quality']\n",
    "X_train = stream_quality_df.drop(['stream_quality'], axis=1)\n",
    "Y_test = stream_quality_test['stream_quality']\n",
    "X_test = stream_quality_test.drop(['stream_quality'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression\n",
      "Accuracy on testset 0.9367969917404226\n",
      "Precision on testset 0.5249247239879559\n",
      "Recall on testset 0.1999490251051357\n",
      "\n",
      "Accuracy on trainset 0.9447748492271971\n",
      "Precision on trainset 0.8499154636493692\n",
      "Recall on trainset 0.23478479557375873\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionFunction(X_train, Y_train, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RidgeClassifier\n",
      "Accuracy on testset 0.9393627153155224\n",
      "Precision on testset 0.6274509803921569\n",
      "Recall on testset 0.14476870141455334\n",
      "\n",
      "Accuracy on trainset 0.9436434383085899\n",
      "Precision on trainset 0.9247367512515104\n",
      "Recall on trainset 0.1924624559890781\n"
     ]
    }
   ],
   "source": [
    "RidgeClassifierFunction(X_train, Y_train, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Balancing of Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification task with balanced and outliers free data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression\n",
      "Accuracy on testset 0.8512413996945762\n",
      "Precision on testset 0.23000289146492128\n",
      "Recall on testset 0.5575379125780553\n",
      "\n",
      "Accuracy on trainset 0.7222921914357683\n",
      "Precision on trainset 0.862835348115586\n",
      "Recall on trainset 0.5286187285141708\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionFunction(X_train_resampled, Y_train_resampled, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RidgeClassifier\n",
      "Accuracy on testset 0.8570707236572029\n",
      "Precision on testset 0.2367500894799152\n",
      "Recall on testset 0.5479164011724226\n",
      "\n",
      "Accuracy on trainset 0.7237800273540019\n",
      "Precision on trainset 0.859626939135748\n",
      "Recall on trainset 0.5349080366902714\n"
     ]
    }
   ],
   "source": [
    "RidgeClassifierFunction(X_train_resampled, Y_train_resampled, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}