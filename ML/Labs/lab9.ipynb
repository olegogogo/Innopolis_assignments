{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLYOztuGtZQr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 9: Techniques for training Deep Neural Netwoks\n",
    "\n",
    "```\n",
    "- Machine Learning, Innopolis University (Fall semester 2022)\n",
    "- Professor: Adil Khan\n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "\n",
    "```\n",
    "In this lab, you will practice techniques that are used to improve deep learning models perfomence in Pytorch.\n",
    "\n",
    "Lab Plan\n",
    "1. Data Augmentation examples\n",
    "2. Batch normalization, Dropout, ...\n",
    "3. Adaptive Learning rate and Optimizers\n",
    "4. Using TensorBoard\n",
    "5. Using Pretrained models (Transfer learning)\n",
    "\n",
    "```\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcGwL_d__qH6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. CNN with PyTorch\n",
    "\n",
    "## Load data and preprocess\n",
    "\n",
    "To load our data set (CIFAR10) we can either download it manualy or use torchvision package. `torchvision` consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "\n",
    "For smooth training of the CNN we need to transform (normalize) the images. `transforms` package conatains common image transformations. Image transformations can be chained together using `transforms.Compose`. In our case we need to first convert image to tensor `transforms.ToTensor()` then normalize `transforms.Normalize`\n",
    "\n",
    "The packages can be pip installed<br>\n",
    "`!pip install torch` <br>\n",
    "`!pip install torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_PBgoYvBzzw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa20689283f748448706ba02242c0172"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "batch_size = 128\n",
    "test_batch_size = 100\n",
    "\n",
    "# Transformations\n",
    "# TODO : add data augmentation of your choice\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     None,\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Create Train Dataloader\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "#Create Test Dataloader\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data visualization \n",
    "Create a simple method to have a look at the data (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torchvision\\datasets\\cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 94, in __call__\n    img = t(img)\nTypeError: 'NoneType' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [3], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# get some random training images\u001B[39;00m\n\u001B[0;32m     12\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(trainloader)\n\u001B[1;32m---> 13\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[43mdataiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# show images\u001B[39;00m\n\u001B[0;32m     16\u001B[0m imshow(torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(images[:\u001B[38;5;241m4\u001B[39m]))\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1376\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1375\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1402\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\_utils.py:461\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    458\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    459\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m--> 461\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mTypeError\u001B[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torchvision\\datasets\\cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\n  File \"D:\\Innopolis\\_my\\env\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 94, in __call__\n    img = t(img)\nTypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lets Switch to the GPU (if available) - why?\n",
    "\n",
    "\n",
    "Unlike TensorFlow, PyTorch doesn’t have a dedicated library for GPU users,so its neccessary to some manual setup <br>\n",
    "<b>NB: </b>If working on Colab, make sure that GPU runtime is enabled <br>\n",
    "<b>NB: </b>It’s not possible to transfer Data Loaders directly to GPU <br>\n",
    "<b>NB: </b> To get total number of GPU devices available `torch.cuda.device_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bH22zyDwCYCf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create a Simple Convolutional neural network (CNN)\n",
    "\n",
    "The simple CNN is made up of 2D Convolutional layers, Pooling layers and fully connected layers. <br> \n",
    "<b>NB : </b> If we succesfully connected to GPU, we need to send our CNN model to GPU for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create the BaseModel by defining the missing (None) convolutional layers, Max pool and fully connected layers\n",
    "#TODO: Finish implementation of foward method in class BaseModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) \n",
    "        \n",
    "        # TODO \n",
    "        self.conv2 = nn.Conv2d(None, 64, 3, padding=1) \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) \n",
    "        \n",
    "        # TODO \n",
    "        self.conv3 = nn.Conv2d(None, 128, 3, padding=1) \n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # TODO \n",
    "        self.fc1 = nn.Linear(None, 256)\n",
    "        self.fc2 = nn.Linear(256, None)\n",
    "        self.output = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the foward pass method. NOTE: Apply Relu activation function to all layers \n",
    "        # order : conv1 -> activation -> conv2 -> activation -> pool1 -> conv3 -> activation -> pool2 -> fc1 -> activation -> fc2 -> activation -> output\n",
    "        # x = F.relu\n",
    "        pass\n",
    "\n",
    "model = BaseModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpsM2vS4F26n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "R1sHQhqFF4Pc",
    "outputId": "94edae09-67f4-4e62-deb3-a386332b4297",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in the CNN model: 2213094\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of params in the CNN model:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pry2xqvdDDGO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yS3Eo37FDKt3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def train_evaluate(net, optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): #TODO: Iterate through the batches and train the cnn\n",
    "            # TODO : get the inputs and place them to the training devide (i.e GPU or CPU) \n",
    "            inputs, labels = None\n",
    "            inputs, labels = None\n",
    "            \n",
    "            # TODO : Train procedure -> zero the gradients, forward pass + backward pass + optimize\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = None\n",
    "            loss = None\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # TODO: print statistics and log loss to Tensorboard\n",
    "        running_loss /= len(trainloader)\n",
    "        print(f'[Epoch {epoch+1}] Loss {running_loss:.4f}')\n",
    "                \n",
    "    print('Finished Training')\n",
    "    \n",
    "    #Print Model overall Accuracy \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    #Print Model classwise Accuracy \n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Simple CNN training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "V_CvS8oBDhL1",
    "outputId": "7c86beb1-139a-4595-a216-d4c8a3896139",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss 2.3017\n",
      "[Epoch 2] Loss 2.2940\n",
      "[Epoch 3] Loss 2.2453\n",
      "[Epoch 4] Loss 2.0382\n",
      "[Epoch 5] Loss 1.8688\n",
      "[Epoch 6] Loss 1.7389\n",
      "[Epoch 7] Loss 1.6463\n",
      "[Epoch 8] Loss 1.5832\n",
      "[Epoch 9] Loss 1.5364\n",
      "[Epoch 10] Loss 1.4968\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "Accuracy of plane : 61 %\n",
      "Accuracy of   car : 75 %\n",
      "Accuracy of  bird : 23 %\n",
      "Accuracy of   cat : 30 %\n",
      "Accuracy of  deer : 28 %\n",
      "Accuracy of   dog : 40 %\n",
      "Accuracy of  frog : 64 %\n",
      "Accuracy of horse : 62 %\n",
      "Accuracy of  ship : 47 %\n",
      "Accuracy of truck : 31 %\n"
     ]
    }
   ],
   "source": [
    "# TODO : define an optimizer SGD with learning rate 0.001 and momentum 0.9\n",
    "optimizer = None\n",
    "train_evaluate(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improved CNN Model\n",
    "\n",
    "### Task \n",
    "1. Add Dropout for both convolution and fully connected layers\n",
    "2. Add Batch Normalization for convolutions\n",
    "3. Add Batch Normalization for fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create the ImprovedModel by defining the missing (None) batch Normalization layers and Dropout\n",
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1),\n",
    "            None , # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            None,  # Dropout 25%\n",
    "            \n",
    "            nn.Conv2d(32,64,3,padding=1),\n",
    "            None, # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            None,  # Dropout 25%\n",
    "            \n",
    "            nn.Conv2d(64,128,3,padding=1),\n",
    "            None, # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            None,  # Dropout 25%\n",
    "            \n",
    "            nn.Conv2d(128,128,3,padding=1),\n",
    "            None , # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(128,128,3,padding=1),\n",
    "            None, # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            None, # Dropout 25%\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(None),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "model_improved = ImprovedModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in the CNN model: 2213094\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of params in the CNN model:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improved CNN training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss 1.5229\n",
      "[Epoch 2] Loss 1.2268\n",
      "[Epoch 3] Loss 1.0909\n",
      "[Epoch 4] Loss 1.0057\n",
      "[Epoch 5] Loss 0.9471\n",
      "[Epoch 6] Loss 0.8981\n",
      "[Epoch 7] Loss 0.8546\n",
      "[Epoch 8] Loss 0.8245\n",
      "[Epoch 9] Loss 0.7930\n",
      "[Epoch 10] Loss 0.7744\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "Accuracy of plane : 84 %\n",
      "Accuracy of   car : 87 %\n",
      "Accuracy of  bird : 52 %\n",
      "Accuracy of   cat : 72 %\n",
      "Accuracy of  deer : 61 %\n",
      "Accuracy of   dog : 68 %\n",
      "Accuracy of  frog : 88 %\n",
      "Accuracy of horse : 84 %\n",
      "Accuracy of  ship : 64 %\n",
      "Accuracy of truck : 79 %\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_improved.parameters(),lr=0.001)\n",
    "train_evaluate(model_improved, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CNN from popular model architectures (Transfer learning)\n",
    "\n",
    "Same procedure as simple CNN but the achitecture of the neural net is much more complicated and the weights are pretrained. <br> \n",
    "\n",
    "\n",
    "### Fine Tuning\n",
    "Fine tuning or transfer learning is the task of training a model on a big dataset and then adjusting the parameters of the model for a smaller task with less data.\n",
    "\n",
    "It is very common in Computer Vision and Natural Language Processing with the immergence of BERT and UMLfit. <br>\n",
    "![](https://miro.medium.com/max/1276/1*ZkPBqU8vx2vAgcLpz9pi5g.jpeg)\n",
    "\n",
    "Say we want to use resnet (trained on imagenet with 1000 classes and has input shape of 256x256)  and fine-tune it for CIFAR10 (has 10 categories with input shape of 32×32)\n",
    "\n",
    "What is the biggest changes that we need to make?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to Import Popular CNN models? \n",
    "\n",
    "`torchvision,models` contains of popular model architectures and can be loaded together with their trained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# resnet18 = models.resnet18(pretrained=True,progress=True)\n",
    "# alexnet = models.alexnet(pretrained=True,progress=True)\n",
    "# squeezenet = models.squeezenet1_0(pretrained=True,progress=True)\n",
    "# vgg16 = models.vgg16(pretrained=True,progress=True)\n",
    "# densenet = models.densenet161(pretrained=True,progress=True)\n",
    "# inception = models.inception_v3(pretrained=True,progress=True)\n",
    "# googlenet = models.googlenet(pretrained=True,progress=True)\n",
    "# shufflenet = models.shufflenet_v2_x1_0(pretrained=True,progress=True)\n",
    "# mobilenet = models.mobilenet_v2(pretrained=True,progress=True)\n",
    "# resnext50_32x4d = models.resnext50_32x4d(pretrained=True,progress=True)\n",
    "# wide_resnet50_2 = models.wide_resnet50_2(pretrained=True,progress=True)\n",
    "# mnasnet = models.mnasnet1_0(pretrained=True,progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Start by loading and transforming the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((256,256)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define CNN model \n",
    "\n",
    "<b>NB : </b>To make the model architecture fit our classification task, we will change the last fully connected layer and train only it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = models.resnet18(weights='IMAGENET1K_V1', progress=True)\n",
    "        self.net.trainable = False # Freeze the layers of the pretrained model\n",
    "        self.net.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Self-practice Task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Add Tensorboard to monitor the train and validation loss, recall, precision and accuracy every after training epoch\n",
    "2. Create another CNN using pretrained model and compare it with already implemented resnet and simple CNN (plot their losses on same tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}