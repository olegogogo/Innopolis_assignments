{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVWoX5adp7bx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Week 14 : Generative Adversarial Networks\n",
    "```\n",
    "- Machine Learning, Innopolis University \n",
    "- Professor: Adil Khan \n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "\n",
    "```\n",
    "Lab Plan\n",
    "    1. Vanila GAN achitecture \n",
    "    2. GAN training procedure\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yMz7v3Yp7cA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Vannila Generative adversarial network (GAN)\n",
    "\n",
    "![caption](https://www.researchgate.net/profile/Zhaoqing-Pan/publication/331756737/figure/fig1/AS:736526694621184@1552613056409/The-architecture-of-generative-adversarial-networks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lE55zaEp7cA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Dataset \n",
    "\n",
    "For this lesson we will use SVHN dataset which readily available in `torchvision` and we will do minimal transformation operations \n",
    "\n",
    "Install `torchvision` : `pip install torchvision`\n",
    "\n",
    "### Task : Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgVjuBIo9YcY",
    "outputId": "7ce0d09b-47d0-4c57-ca21-1b9bb0c7c7b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def normalize(data_tensor):\n",
    "    '''re-scale image values to [-1, 1]'''\n",
    "    return (data_tensor / 255.) * 2. - 1. \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: normalize(x))])\n",
    "\n",
    "# SVHN training datasets\n",
    "svhn_train = datasets.SVHN(root='data/', split='train', download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "# build DataLoaders for SVHN dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=svhn_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gol3RnPYtIbX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwRO4sTip7cC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 Generator & Discriminator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OyAK6ydmp7cC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#ngf : Number of generator filters\n",
    "#ndf : Number of discriminator filters\n",
    "nz = 32\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, ndf=3, conv_dim=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, 1, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5*5,1),\n",
    "            nn.Sigmoid()\n",
    "          )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step 1: pass the input (real or fake samples) through all hidden layers\n",
    "        return self.model(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_size, ngf, conv_dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        # Step 1: Define the generator network architecture\n",
    "        # NOTE: the input is the random noise size and output is conv_dim i.e (3,32,32)\n",
    "        self.conv_dim = conv_dim \n",
    "        self.input_layer = nn.Linear(in_features=z_size, out_features=2048, bias=True)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels=ngf * 2, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features= ngf * 2),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=ngf),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "      # Step 1: pass the input which is random noise to generate the face samples\n",
    "      x = self.input_layer(x)\n",
    "      x = x.view(-1, self.conv_dim*4, 4, 4) # (batch_size, depth, 4, 4)\n",
    "      return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epToMkpwp7cD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3 Set hyperparams and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RgJwvYBp7cD",
    "outputId": "54c46b18-5918-4b1d-d18b-f4c51fdd7ea6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8): Linear(in_features=25, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "Generator(\n",
      "  (input_layer): Linear(in_features=100, out_features=2048, bias=True)\n",
      "  (model): Sequential(\n",
      "    (0): ConvTranspose2d(128, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "    (3): ConvTranspose2d(6, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Tanh()\n",
      "    (6): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define hyperparams\n",
    "conv_dim = 32\n",
    "z_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define discriminator and generator\n",
    "D = Discriminator(conv_dim).to(device)\n",
    "G = Generator(z_size=z_size, ngf=3,conv_dim=conv_dim).to(device)\n",
    "\n",
    "#print the models summary \n",
    "print(D)\n",
    "print()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHnvFXdzp7cE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.4 Define the loss function for D(x) and G(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b6KcJQGIp7cE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def real_loss(D_out, smooth=False):\n",
    "    batch_size = D_out.size(0)\n",
    "    # label smoothing\n",
    "    if smooth:\n",
    "        # smooth, real labels\n",
    "        labels = torch.FloatTensor(batch_size).uniform_(0.9, 1).to(device)\n",
    "    else:\n",
    "        labels = torch.ones(batch_size) # real labels = 1\n",
    "    # move labels to GPU if available     \n",
    "    \n",
    "    labels = labels.to(device)\n",
    "    # binary cross entropy with logits loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "def fake_loss(D_out):\n",
    "    batch_size = D_out.size(0)\n",
    "    labels = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device) # fake labels = 0\n",
    "    labels = labels.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # calculate loss\n",
    "    loss = criterion(D_out.squeeze(), labels)\n",
    "    return loss\n",
    "\n",
    "# params\n",
    "learning_rate = 0.0003\n",
    "beta1=0.5\n",
    "beta2=0.999 # default value\n",
    "\n",
    "# Create optimizers for the discriminator and generator\n",
    "d_optimizer = None\n",
    "g_optimizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkWInd2sp7cG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.5 GAN training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tQDq36wp7cG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "losses = []\n",
    "\n",
    "print_every = 2\n",
    "\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size=16\n",
    "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images, _) in enumerate(train_loader):\n",
    "                \n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        \n",
    "        # TRAIN THE DISCRIMINATOR\n",
    "        # Step 1: Zero gradients (zero_grad)\n",
    "        # Step 2: Train with real images\n",
    "        # Step 3: Compute the discriminator losses on real images \n",
    "        \n",
    "        D_real = None\n",
    "        d_real_loss = real_loss(D_real)\n",
    "        \n",
    "        # Step 4: Train with fake images\n",
    "        # Step 5: Generate fake images and move x to GPU, if available\n",
    "        # Step 6: Compute the discriminator losses on fake images \n",
    "        # Step 7: add up loss and perform backprop\n",
    "        \n",
    "        fake_images = None     \n",
    "        \n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #TRAIN THE GENERATOR (Train with fake images and flipped labels)\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # Step 1: Zero gradients  \n",
    "        # Step 2: Generate fake images from random noise (z)\n",
    "        # Step 3: Compute the discriminator losses on fake images using flipped labels!\n",
    "        # Step 4: Perform backprop and take optimizer step\n",
    "\n",
    "    # Print some loss stats\n",
    "    if epoch % print_every == 0:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQsNSLUy-sbV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Keep in mind:\n",
    "\n",
    "1. Always use a learning rate for discriminator higher than the generator.\n",
    "\n",
    "2. Keep training even if you see that the losses are going up.\n",
    "\n",
    "3. There are many variations with different loss functions which are worth exploring.\n",
    "\n",
    "4. If you get mode collapse, lower the learning rates.\n",
    "\n",
    "5. Adding noise to the training data helps make the model more stable.\n",
    "\n",
    "6. Label Smoothing: instead of making the labels as 1 make it 0.9 \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AML_Lab9_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
