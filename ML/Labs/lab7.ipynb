{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Self-practice Task\n",
    "\n",
    "Train a CNN model and predict the categories in `Caltech 256` dataset:\n",
    "1. Load the data from `torchvision.datasets.Caltech256`\n",
    "1. Split the data to train, validation and test\n",
    "1. Define a CNN model with achitecture of your choice\n",
    "1. Train the model and log the loss and accuracy at every epoch (on train, validation and test set)\n",
    "1. Use a pretrained (such as `VGG16`) model for the same task and compare the models number of parameters together with accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import Caltech256\n",
    "from torchvision.models import vgg16\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "dataset = Caltech256(root='./', download=True)\n",
    "dataset.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list = glob('./caltech256/*/*/*.jpg')\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_list, end_size=(100,100)):\n",
    "        self.image_lsit = image_list\n",
    "        self.end_size = end_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.image_lsit))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = plt.imread(self.image_lsit[i])\n",
    "        image = Image.fromarray(image).convert('RGB')\n",
    "        image = np.asarray(image).astype(np.float) / 255\n",
    "        image = torch.tensor(image, dtype=torch.float).permute([2,0,1])\n",
    "        image = Resize(size=self.end_size)(image)\n",
    "        label = torch.tensor(int(image_list[i].split('\\\\')[3][:3]), dtype=torch.uint8)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "random.shuffle(image_list)\n",
    "train_val_test_size = [0.6,0.2,0.2]\n",
    "x_train = image_list[:int(len(image_list)*train_val_test_size[0])]\n",
    "x_val = image_list[len(x_train):len(x_train)+int(len(image_list)*train_val_test_size[1])]\n",
    "x_test = image_list[-int(len(image_list)*train_val_test_size[2]):]\n",
    "\n",
    "x_train = ImageDataset(x_train)\n",
    "x_test = ImageDataset(x_test)\n",
    "x_val = ImageDataset(x_val)\n",
    "\n",
    "x_train = DataLoader(dataset=x_train, batch_size=batch_size, shuffle=False, pin_memory_device='cpu')\n",
    "x_test = DataLoader(dataset=x_test, batch_size=batch_size, shuffle=False, pin_memory_device='cpu')\n",
    "x_val = DataLoader(dataset=x_val, batch_size=batch_size, shuffle=False, pin_memory_device='cpu')\n",
    "\n",
    "torch.cuda.memory_reserved(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CNN_1(nn.Module):\n",
    "    # Convolution formula: ((n + 2p - f) / s) + 1\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_1, self).__init__()\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(3, 10, kernel_size=5))\n",
    "        self.layers.append(nn.MaxPool2d(2))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Conv2d(10, 20, kernel_size=5))\n",
    "        self.layers.append(nn.Dropout2d())\n",
    "        self.layers.append(nn.MaxPool2d(2))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Flatten(1))\n",
    "        self.layers.append(nn.Linear(9680, 2048)) # calculated manually\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(p=0.5))\n",
    "        self.layers.append(nn.Linear(2048, 256))\n",
    "        self.layers.append(nn.LogSoftmax(1))\n",
    "\n",
    "        for i, n in enumerate(self.layers):\n",
    "            self.add_module(f'layer_{i}' ,n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Exercise: calclulate shape after each layer\n",
    "        for n in self.children():\n",
    "            #print(n)\n",
    "            x = n(x)\n",
    "        #print(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval=700):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thornail/anaconda3/envs/DS_1/lib/python3.9/site-packages/torch/utils/data/dataloader.py:645: UserWarning: pin memory device is set and pin_memory flag is not used then device pinned memory won't be usedplease set pin_memory to true, if you need to use the device pin memory\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_18686/31108544.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  image = np.asarray(image).astype(np.float) / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/18364 (0%)]\tLoss: 5.540532\n",
      "Train Epoch: 1 [6400/18364 (35%)]\tLoss: 5.535106\n",
      "Train Epoch: 1 [12800/18364 (70%)]\tLoss: 5.597634\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "momentum=0.5\n",
    "log_interval = 400\n",
    "device = 'cpu'\n",
    "epochs = 3\n",
    "\n",
    "model_s = CNN_1().to(device)\n",
    "optimizer = optim.SGD(model_s.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_s, device, x_train, optimizer, epoch, log_interval)\n",
    "    test(model_s, device, x_val)\n",
    "    torch.save(model_s.state_dict(), \"My_c256.pt\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CNN_1().to(device)\n",
    "\n",
    "for i, n in enumerate(x_train):\n",
    "    data = n[0].to(device)\n",
    "    print(data.shape)\n",
    "    print(model.forward(data).shape)\n",
    "    if i == 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_vgg = vgg16(pretrained=True).cuda()\n",
    "model_vgg.add_module(\"End ReLu\", nn.ReLU())\n",
    "model_vgg.add_module(\"End linear\", nn.Linear(1000, 256))\n",
    "model_vgg.add_module(\"Softmax\", nn.LogSoftmax(1))\n",
    "for n in model_vgg.children():\n",
    "    print(n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 0.000001\n",
    "momentum=0.5\n",
    "log_interval = 300\n",
    "device = 'cpu'\n",
    "epochs = 2\n",
    "\n",
    "optimizer = optim.SGD(model_vgg.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_vgg, device, x_train, optimizer, epoch, log_interval)\n",
    "    test(model_vgg, device, x_val)\n",
    "    torch.save(model_s.state_dict(), \"vgg16.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}