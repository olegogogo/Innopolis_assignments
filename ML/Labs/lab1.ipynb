{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Week 1 : Data Manipulation and Exploration\n",
    "```\n",
    "- Machine Learning, Innopolis University (Fall semester 2022)\n",
    "- Professor: Adil Khan\n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "\n",
    "### Content\n",
    "```\n",
    "Lab Plan\n",
    "1. Data exploration\n",
    "2. Dealing with categorical features\n",
    "3. Dealing with missing data\n",
    "4. Features Scaling\n",
    "5. Trainset splitting\n",
    "6. Data Visualization\n",
    "\n",
    "```\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "![](https://www.gosmar.eu/machinelearning/wp-content/uploads/2021/01/MLOps_pipeline_scaling3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test for libraries installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Read Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "football_df = pd.read_csv('./football_data.csv', low_memory=False)\n",
    "\n",
    "football_df.drop(['Date', 'time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>TimeUnder</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>PlayTimeDiff</th>\n",
       "      <th>SideofField</th>\n",
       "      <th>yrdln</th>\n",
       "      <th>yrdline100</th>\n",
       "      <th>...</th>\n",
       "      <th>yacEPA</th>\n",
       "      <th>Home_WP_pre</th>\n",
       "      <th>Away_WP_pre</th>\n",
       "      <th>Home_WP_post</th>\n",
       "      <th>Away_WP_post</th>\n",
       "      <th>Win_Prob</th>\n",
       "      <th>WPA</th>\n",
       "      <th>airWPA</th>\n",
       "      <th>yacWPA</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016121101</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SD</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016121101</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SD</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330475</td>\n",
       "      <td>0.968025</td>\n",
       "      <td>0.031975</td>\n",
       "      <td>0.940170</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>0.031975</td>\n",
       "      <td>0.027855</td>\n",
       "      <td>0.024299</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016121101</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>CAR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.940170</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.052425</td>\n",
       "      <td>0.059830</td>\n",
       "      <td>-0.007405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016121101</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>CAR</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.766159</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.052425</td>\n",
       "      <td>0.953601</td>\n",
       "      <td>0.046399</td>\n",
       "      <td>0.052425</td>\n",
       "      <td>-0.006025</td>\n",
       "      <td>0.036136</td>\n",
       "      <td>-0.042161</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016121101</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>CAR</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.953601</td>\n",
       "      <td>0.046399</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.087646</td>\n",
       "      <td>0.046399</td>\n",
       "      <td>0.041247</td>\n",
       "      <td>0.041247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GameID  Drive  qtr  down  TimeUnder  TimeSecs  PlayTimeDiff  \\\n",
       "0  2016121101     13    2   NaN          2    1920.0           5.0   \n",
       "1  2016121101     13    2   1.0          2    1920.0           0.0   \n",
       "2  2016121101     13    2   1.0          2    1910.0          10.0   \n",
       "3  2016121101     13    2   2.0          2    1877.0          33.0   \n",
       "4  2016121101     13    2   3.0          2    1868.0           9.0   \n",
       "\n",
       "  SideofField  yrdln  yrdline100  ...    yacEPA  Home_WP_pre  Away_WP_pre  \\\n",
       "0          SD   44.0        44.0  ...       NaN          NaN          NaN   \n",
       "1          SD   47.0        53.0  ...  0.330475     0.968025     0.031975   \n",
       "2         CAR    7.0         7.0  ...       NaN     0.940170     0.059830   \n",
       "3         CAR    9.0         9.0  ... -3.766159     0.947575     0.052425   \n",
       "4         CAR    9.0         9.0  ...  0.000000     0.953601     0.046399   \n",
       "\n",
       "   Home_WP_post Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n",
       "0           NaN          NaN  0.000000       NaN       NaN       NaN    2016  \n",
       "1      0.940170     0.059830  0.031975  0.027855  0.024299  0.003556    2016  \n",
       "2      0.947575     0.052425  0.059830 -0.007405       NaN       NaN    2016  \n",
       "3      0.953601     0.046399  0.052425 -0.006025  0.036136 -0.042161    2016  \n",
       "4      0.912354     0.087646  0.046399  0.041247  0.041247  0.000000    2016  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number categorical featues: 36\n",
      "GameID         int64\n",
      "Drive          int64\n",
      "qtr            int64\n",
      "down         float64\n",
      "TimeUnder      int64\n",
      "              ...   \n",
      "Win_Prob     float64\n",
      "WPA          float64\n",
      "airWPA       float64\n",
      "yacWPA       float64\n",
      "Season         int64\n",
      "Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "types = football_df.dtypes\n",
    "print(\"Number categorical featues:\", sum(types=='object'))\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>TimeUnder</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>PlayTimeDiff</th>\n",
       "      <th>yrdln</th>\n",
       "      <th>yrdline100</th>\n",
       "      <th>ydstogo</th>\n",
       "      <th>...</th>\n",
       "      <th>yacEPA</th>\n",
       "      <th>Home_WP_pre</th>\n",
       "      <th>Away_WP_pre</th>\n",
       "      <th>Home_WP_post</th>\n",
       "      <th>Away_WP_post</th>\n",
       "      <th>Win_Prob</th>\n",
       "      <th>WPA</th>\n",
       "      <th>airWPA</th>\n",
       "      <th>yacWPA</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>8448.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9992.000000</td>\n",
       "      <td>9984.000000</td>\n",
       "      <td>9980.000000</td>\n",
       "      <td>9980.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3929.000000</td>\n",
       "      <td>9357.000000</td>\n",
       "      <td>9357.000000</td>\n",
       "      <td>9309.000000</td>\n",
       "      <td>9309.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9.845000e+03</td>\n",
       "      <td>3930.000000</td>\n",
       "      <td>3923.000000</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.016372e+09</td>\n",
       "      <td>12.444900</td>\n",
       "      <td>2.584500</td>\n",
       "      <td>1.991951</td>\n",
       "      <td>7.322400</td>\n",
       "      <td>1686.264011</td>\n",
       "      <td>20.739283</td>\n",
       "      <td>28.566433</td>\n",
       "      <td>47.859218</td>\n",
       "      <td>7.158400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400785</td>\n",
       "      <td>0.547408</td>\n",
       "      <td>0.453126</td>\n",
       "      <td>0.547667</td>\n",
       "      <td>0.452708</td>\n",
       "      <td>0.470946</td>\n",
       "      <td>1.673133e-03</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.996451e+05</td>\n",
       "      <td>7.075561</td>\n",
       "      <td>1.131542</td>\n",
       "      <td>1.006399</td>\n",
       "      <td>4.685216</td>\n",
       "      <td>1064.437980</td>\n",
       "      <td>20.795996</td>\n",
       "      <td>12.533362</td>\n",
       "      <td>24.737534</td>\n",
       "      <td>4.844632</td>\n",
       "      <td>...</td>\n",
       "      <td>2.008014</td>\n",
       "      <td>0.300660</td>\n",
       "      <td>0.300744</td>\n",
       "      <td>0.302591</td>\n",
       "      <td>0.302650</td>\n",
       "      <td>0.319106</td>\n",
       "      <td>4.684680e-02</td>\n",
       "      <td>0.056720</td>\n",
       "      <td>0.065689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016121e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-849.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.156367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.719480e-01</td>\n",
       "      <td>-0.943119</td>\n",
       "      <td>-0.939447</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.016122e+09</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950799</td>\n",
       "      <td>0.298087</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.179571</td>\n",
       "      <td>0.172491</td>\n",
       "      <td>-1.375776e-02</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.016122e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565156</td>\n",
       "      <td>0.435096</td>\n",
       "      <td>0.568334</td>\n",
       "      <td>0.431754</td>\n",
       "      <td>0.486653</td>\n",
       "      <td>-7.985673e-07</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.017010e+09</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469628</td>\n",
       "      <td>0.817714</td>\n",
       "      <td>0.702465</td>\n",
       "      <td>0.820549</td>\n",
       "      <td>0.705156</td>\n",
       "      <td>0.750169</td>\n",
       "      <td>1.278280e-02</td>\n",
       "      <td>0.033391</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.017010e+09</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>908.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.079540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.739204e-01</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.932194</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GameID         Drive           qtr         down     TimeUnder  \\\n",
       "count  1.000000e+04  10000.000000  10000.000000  8448.000000  10000.000000   \n",
       "mean   2.016372e+09     12.444900      2.584500     1.991951      7.322400   \n",
       "std    3.996451e+05      7.075561      1.131542     1.006399      4.685216   \n",
       "min    2.016121e+09      1.000000      1.000000     1.000000      0.000000   \n",
       "25%    2.016122e+09      6.000000      2.000000     1.000000      3.000000   \n",
       "50%    2.016122e+09     12.000000      3.000000     2.000000      7.000000   \n",
       "75%    2.017010e+09     18.000000      4.000000     3.000000     11.000000   \n",
       "max    2.017010e+09     30.000000      5.000000     4.000000     15.000000   \n",
       "\n",
       "          TimeSecs  PlayTimeDiff        yrdln   yrdline100       ydstogo  ...  \\\n",
       "count  9992.000000   9984.000000  9980.000000  9980.000000  10000.000000  ...   \n",
       "mean   1686.264011     20.739283    28.566433    47.859218      7.158400  ...   \n",
       "std    1064.437980     20.795996    12.533362    24.737534      4.844632  ...   \n",
       "min    -849.000000      0.000000     1.000000     1.000000      0.000000  ...   \n",
       "25%     772.000000      5.000000    19.000000    29.000000      3.000000  ...   \n",
       "50%    1800.000000     18.000000    30.000000    48.000000      9.000000  ...   \n",
       "75%    2575.000000     37.000000    38.000000    69.000000     10.000000  ...   \n",
       "max    3600.000000    908.000000    50.000000    99.000000     36.000000  ...   \n",
       "\n",
       "            yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  Away_WP_post  \\\n",
       "count  3929.000000  9357.000000  9357.000000   9309.000000   9309.000000   \n",
       "mean     -0.400785     0.547408     0.453126      0.547667      0.452708   \n",
       "std       2.008014     0.300660     0.300744      0.302591      0.302650   \n",
       "min     -12.156367     0.000000     0.000000      0.000000      0.000000   \n",
       "25%      -0.950799     0.298087     0.183309      0.295898      0.179571   \n",
       "50%       0.000000     0.565156     0.435096      0.568334      0.431754   \n",
       "75%       0.469628     0.817714     0.702465      0.820549      0.705156   \n",
       "max       8.079540     1.000000     1.000000      1.000000      1.000000   \n",
       "\n",
       "           Win_Prob           WPA       airWPA       yacWPA   Season  \n",
       "count  10000.000000  9.845000e+03  3930.000000  3923.000000  10000.0  \n",
       "mean       0.470946  1.673133e-03     0.014596    -0.009764   2016.0  \n",
       "std        0.319106  4.684680e-02     0.056720     0.065689      0.0  \n",
       "min        0.000000 -9.719480e-01    -0.943119    -0.939447   2016.0  \n",
       "25%        0.172491 -1.375776e-02    -0.009758    -0.017638   2016.0  \n",
       "50%        0.486653 -7.985673e-07     0.004151     0.000000   2016.0  \n",
       "75%        0.750169  1.278280e-02     0.033391     0.009991   2016.0  \n",
       "max        1.000000  9.739204e-01     0.898214     0.932194   2016.0  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Profiling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "report = ProfileReport(football_df)\n",
    "# report.to_file('data_profile_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### One-hot-encoding of categorical feature\n",
    "1. Why to encode the categorical feature?\n",
    "<span style=\"color:blue\">Because most of the machine learning and basic deep learning algorithms can only accept numerical data and features.</span>\n",
    "2. Why one-hot-encoding form? why not give each category in the feature a specific code value?\n",
    "<span style=\"color:blue\"> Giving each category a number (e.g. giving categories: red, blue, black -> 1, 2, 3) will indicate to the learning algorithm that there's some ordering (e.g., black is larger than red) which is not true as the categories are nominal.\n",
    "3. How many new features will be added? What if we have some missing values, which is the case in this dataset?\n",
    "<span style=\"color:blue\"> Usually the number of new features is #categories - 1, as one indicator variable can be infered from the others (e.g., if not black and blue then it is red for sure, so black -> [1, 0], blue -> [0, 1], red -> [0, 0]). But if the trainset may have empty values for this feature, and there's a posibility that the testset also has empty cells for this feature, then it is better to have #categories new features to indicate missing value (i.e., black -> [1, 0, 0], blue -> [0, 1, 0], red -> [0, 0, 1], NA -> [0, 0, 0]).\n",
    "\n",
    "4. When is it appropriate to give each category an encoding value?\n",
    "<span style=\"color:blue\"> It will be appropriate if the categorical feature is ordinal (e.g, small, medium, large). Then it is reasonable approach to give them ordered values without transform it to one-hot-encoding form (i.e., small -> 1, medium -> 2, large -> 3)\n",
    "\n",
    "<span style=\"color:red\"> Task : In the next cell, implement the function that take a dataframe, name of the categorical feature, and the encoder object. Then, adds new features that represent the one-hot-encoding form of this feature and ignore the missing values in it (encode them to zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "cat_feats = football_df.select_dtypes(include=['object']).columns.tolist()\n",
    "encoder = OneHotEncoder(cols=cat_feats, handle_unknown='ignore')\n",
    "\n",
    "encoder.fit(football_df)\n",
    "\n",
    "# Write your code here (1 line)\n",
    "# Transform the data \n",
    "encoded_data = encoder.transform(football_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Data Imputation\n",
    "#### Imputation is filling the missing values in the dataset.\n",
    "Several issues to address:\n",
    "1. Why we should fill them? Why not remove the rows that has missing values?\n",
    "<span style=\"color:blue\"> Most of the machine learning algorithms can't deal with missing values cell (NA/NAN). Removing the rows/cols that have missing values could be an option when the missing values in some rows/cols is a few and the to-be-deleted rows/cols are few comparing to what's left (removing 50 rows out of 10k rows that have 50 empty values on average for 80 features). However, the usual case it not be deleted (why?), Some information will be lost due to the deletion which is the non-missing values, so it is better not to lose them.\n",
    "2. Filling it with constant value for each value, but what's it?\n",
    "<span style=\"color:blue\"> Estimating a constant value that best to represent the feature is trivially chosen to be the expected value of this feature, which is the mean. Other options is to use some other central tendency measures like the median, mode or mid-range but the best practice is to use mean or median for numerical continuous features and use mode for the discrete ones.\n",
    "3. (Advanced) Estimate the filling value, each row for its own.\n",
    "<span style=\"color:blue\"> There's another option of filling the missing values is to infer them from the rest of the data by regression/classification models (one for each feature).\n",
    "This method is out of the level of this course so you can read about it [here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer) and [here](https://www.kaggle.com/shashankasubrahmanya/missing-data-imputation-using-regression).\n",
    "4. How to choose the imputation strategy?\n",
    "<span style=\"color:blue\"> It can be treated as a hyperparamter and choose the best option using a validation set or cross-validation (to be explained).\n",
    "4. (Not related only to imputations) Why we fit the imputer to the training data not the concatenation of both train and test set?\n",
    "<span style=\"color:blue\"> This would cause data leakage to the model. This means the model got some information from the testset which shouldn't be considered at all before the testing step. So, the testset shouldn't affect the preprocessing in anyway (e.g., data imputation or scaling).\n",
    "Same goes for validation set.\n",
    "\n",
    "<span style=\"color:red\">Task :  In the next cell, implement a function that returns the count of nan/empty cells in a dataframe.</span><br>\n",
    "<span style=\"color:red\">Task : Use SimpleImputer object, fit it to the trainset, then transform both the train and test sets.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Empty missing data cells in the dataset =  42015\n",
      "After Imputing:\n",
      "#Empty cells in dataset = 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "#TODO: Complete a function that returns number of empty cells \n",
    "def count_nans(df):\n",
    "    # 1 or 2 lines.\n",
    "    return np.sum(np.sum(np.isnan(df))) #np.count_nonzero(~np.isnan(df))\n",
    "\n",
    "# Print number of empty cells (1 line)\n",
    "print(\"#Empty missing data cells in the dataset = \", count_nans(encoded_data))\n",
    "\n",
    "# Write your code here (4 lines):\n",
    "# create the imputer object.\n",
    "# fit the imputer.\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(encoded_data)\n",
    "imputed_data = imputer.transform(encoded_data)\n",
    "\n",
    "print(\"After Imputing:\")\n",
    "# Print number of empty cells in the data(1 line)\n",
    "print(\"#Empty cells in dataset =\", count_nans(imputed_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Features Scaling\n",
    "1. Why we need to make all the features have same range of values?\n",
    "<span style=\"color:blue\"> This has something to do with some machine learning algorithms.\n",
    "First, gradient-related algorithms (e.g., linear regression, logisitic regression, deep learning algorithms): feature scaling is important for the congergence of the algorithms as the gradient in one direction/feature could need more/long steps than the others and the scaling solves this issue and make the training stable and relatively faster.\n",
    "Second, distance related algorithms (e.g., KNN, K-means). These algorithms depends on the distance between samples both in training and testing. Having features with different ranges would affect the distance measure and produce biased prediciton to the features with larger range.\n",
    "for example: having two features (length in KM [10: 10000] and temperature in CÂ° [20: 40]). The distance value will be much affected by the length feature.</span>\n",
    "\n",
    "1. What are the different strategies to scale the features? <br>\n",
    "    * <span style=\"color:blue\">Min-Max scaling: transform all features to fall in this range: [0, 1].</span><br>\n",
    "$$x_i = \\frac{x_i - min(\\mathbf{x})}{max(\\mathbf{x}) - min(\\mathbf{x})}$$\n",
    "    * <span style=\"color:blue\">Standard scaling: transform all features to have mean = 0 and standard deviation = 1. And by assuming that all features follow normal distribution, we can say that standard scaling turns featrues to be $\\sim N(0,1)$.</span> <br>\n",
    "$$x_i = \\frac{x_i - mean(\\mathbf{x})}{stdev(\\mathbf{x})}$$ <br>\n",
    "    * <span style=\"color:blue\">Robust scaling: robust to the outliers that may affect the previous methods in calculating their mean, stdev, min, or max. It uses the interquartile range to scale the features according to it.\n",
    "Interquartile is the range between the 1st quartile and 3rd quartile.</span> <br>\n",
    "$$x_i = \\frac{x_i - Q_1(\\mathbf{x})}{Q_3(\\mathbf{x}) - Q_1(\\mathbf{x})}$$ \n",
    "\n",
    "3. How to choose the strategy?\n",
    "<span style=\"color:blue\">Same as in imputation strategy, using a validation set or using cross-validation.\n",
    "\n",
    "<span style=\"color:red\">  In the following cell, scale all the features with a scaler from your choice. Fit the scaler on the full data set and transform both it.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here (5 lines):\n",
    "# choose the scaler class.\n",
    "# create the scaler object.\n",
    "# fit it to the data.\n",
    "# transform the data\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "scaler.fit(imputed_data)\n",
    "scaled_data = scaler.transform(imputed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Trainset splitting\n",
    "Issues that lead to trainset splitting:\n",
    "1. How we will measure the performance of our model?\n",
    "<span style=\"color:blue\"> Measuring performance on the trainset is not a good idea intuitively, as to estimate the generalization error, we need to evaluate the model on a data that wasn't seen before.\n",
    "So we need to split the dataset that we have to two parts trainset and testset.\n",
    "2. How we will tune the hyperparamters? Can it be done with testset?\n",
    "<span style=\"color:blue\"> If we tuned the hyperparamters on the testset, this will be considered as Data leakage as the hyperparams were tuned on the set that represent the evaluation, so there's a high chance that it will overfit the testset and fails to generalize (i.e., get high test accuracy but fails in production for example).\n",
    "So, it is a must to split the data into 3 parts:\n",
    "(70%) trainset to train the params , (10%) validation set to tune the hyperparameters (it can be used for other stuff like early stopping (tbe)), and (20%) testset to evaluate the model finally.\n",
    "\n",
    "Issues to think of:\n",
    "1. Is is the best strategy to get the best estimate for the true risk/performance of the system?\n",
    "<span style=\"color:blue\"> There's a chance that the testset is biased. So, a better way to estimate the true generalization error is to use cross validation.\n",
    "Cross validation is a method where the dataset, is divided into k equally sized folds then we train on k-1 folds and test on the left one and repeat this process k times for each fold and get k estimates, finally we average all of these k accuracies to represent the final accuracy.\n",
    "2. (Advanced) How to choose between two models?\n",
    "If you have two models one with test accuracy 90% and the other with 91% (averaged from cross valdiation), which one to choose?\n",
    "<span style=\"color:blue\"> The naive/fast approach is to use the model with higher accuracy. But what if these estimates are not significantly different (we got them by chance), then a hypothesis test needs to be done.\n",
    "After testing each model for each fold from the k-folds we can use \"Paired t-test\" to test if they are significantly different or not.\n",
    "<br />(more advanced way, which is used in industry: A/B testing, watch about it [here](https://www.youtube.com/watch?v=zFMgpxG-chM))\n",
    "\n",
    "<span style=\"color:red\"> TASK : In the next task, you will split your data into 3 parts, train, test, and validation by ratios: 70%, 20%, and 10% respectively.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 13035) (2000, 13035) (1000, 13035)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Write your code here (2 lines)\n",
    "x_train, x_test, = train_test_split(scaled_data, test_size=0.2)\n",
    "x_train, x_val = train_test_split(x_train, test_size=1/8)\n",
    "\n",
    "print(x_train.shape, x_test.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 7. Data Visualization\n",
    "Visualization is key-issue to get some insights and intuition about your dataset.\n",
    "How to plot 259 features (259-dimensional data)? what we can plot -at maximum- is 2d or 3d data.\n",
    "\n",
    "Hint: We should reduce the dimension. Read this [article](https://towardsdatascience.com/dimensionality-reduction-ways-and-intuitions-1b5e97592d8e).\n",
    "\n",
    "So, Let's use UMAP to reduce the dimension of this dataset to be 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dim_reducer = PCA(n_components=2)\n",
    "x_train_reduced = dim_reducer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's plot the reduced dataset on a 2D plane.\n",
    "Use matplotlib to make a scatter plot for the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Write code to plot the reduced dataset in a scatter plot.\n",
    "plt.scatter(x_train_reduced[:, 0], x_train_reduced[:, 1], marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 8. Self Practice task\n",
    "\n",
    "Using the Football dataset follow the steps below:\n",
    "1. Select `Win_Prob` as target variable \n",
    "1. Remove columns with constant value (i.e all the values in the column are equal to zero)\n",
    "1. Extract features from `Date` and `time` column\n",
    "1. Remove all columns with more than 99% missing values\n",
    "1. Remove all columns with 99% distinct values\n",
    "1. Split the data into train (80%) and test(20%) sets. \n",
    "1. Split the train data into train (80%) and validation sets. \n",
    "1. Encode categorical data using a different encoder (not One Hot encoder) : see [Category Encoders](https://contrib.scikit-learn.org/category_encoders/index.html) for a full list. remember that you fit the encoder on train data only and then transform test data\n",
    "1. Impute missing values\n",
    "\n",
    "<span style=\"color:red\"> NOTE : Make use of the insights from pandas profiling report</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "football_df = pd.read_csv('./materials/football_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 102)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Task 1\n",
    "Y_data = football_df['Win_Prob']\n",
    "football_df.drop(['Win_Prob'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Task 2\n",
    "for i in football_df.columns:\n",
    "    if football_df[i].unique().shape[0]/10000 == 1:\n",
    "        football_df.drop([i], axis=1, inplace=True)\n",
    "        print(i, ' was dropped')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   time\n0  2016-12-11  02:00\n1  2016-12-11  02:00\n2  2016-12-11  01:50\n3  2016-12-11  01:17\n4  2016-12-11  01:08",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-12-11</td>\n      <td>02:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-12-11</td>\n      <td>02:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-12-11</td>\n      <td>01:50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-12-11</td>\n      <td>01:17</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-12-11</td>\n      <td>01:08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3\n",
    "Datetime = pd.DataFrame([football_df['Date'],football_df['time']]).T\n",
    "Datetime.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoPointConv  was dropped\n",
      "DefTwoPoint  was dropped\n",
      "BlockingPlayer  was dropped\n",
      "RecFumbTeam  was dropped\n",
      "RecFumbPlayer  was dropped\n",
      "ChalReplayResult  was dropped\n"
     ]
    }
   ],
   "source": [
    "# Task 4\n",
    "for i in football_df.columns:\n",
    "    if football_df[i].isnull().sum()/10000 > 0.99:\n",
    "        football_df.drop([i], axis=1, inplace=True)\n",
    "        print(i, ' was dropped')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Task 5\n",
    "for i in football_df.columns:\n",
    "    if football_df[i].unique().shape[0]/10000 >= 0.99:\n",
    "        football_df.drop([i], axis=1, inplace=True)\n",
    "        print(i, ' was dropped')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Task 6 and 7\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test, = train_test_split(football_df,Y_data, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val, = train_test_split(x_train,y_train, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "      Date      GameID  Drive  qtr  down  time  TimeUnder  TimeSecs  \\\n8658     1  2017010104      7    2   1.0     1          8    2221.0   \n924      2  2016121112     22    4   1.0     2         13     770.0   \n4483     3  2016122400      5    1   2.0     3          5    2971.0   \n6379     3  2016122409     13    2   4.0     4          1    1813.0   \n4954     3  2016122405     15    3   1.0     5          8    1361.0   \n...    ...         ...    ...  ...   ...   ...        ...       ...   \n9117     1  2017010112      1    1   1.0   263         15    3554.0   \n2490     4  2016121805     21    4   2.0   478          6     352.0   \n7908     1  2017010108     27    5   1.0   803          5    -623.0   \n728      2  2016121108     13    3   NaN   811          8    1333.0   \n6378     3  2016122409     13    2   NaN     4          1    1813.0   \n\n      PlayTimeDiff  SideofField  ...    airEPA    yacEPA  Home_WP_pre  \\\n8658           9.0            1  ...       NaN       NaN     0.034503   \n924           43.0            2  ...       NaN       NaN     0.000006   \n4483          29.0            3  ...       NaN       NaN     0.337616   \n6379           0.0            4  ...       NaN       NaN     0.738830   \n4954          32.0            5  ...  2.585387 -3.333391     0.868989   \n...            ...          ...  ...       ...       ...          ...   \n9117           5.0           20  ... -0.544715  1.016787     0.543997   \n2490           8.0           24  ... -0.728169 -0.000420     0.671100   \n7908          35.0            6  ...  0.443135 -0.904967     0.575321   \n728           39.0           27  ...       NaN       NaN          NaN   \n6378          14.0            4  ...       NaN       NaN          NaN   \n\n      Away_WP_pre  Home_WP_post  Away_WP_post       WPA    airWPA    yacWPA  \\\n8658     0.965497      0.036645      0.963355 -0.002142       NaN       NaN   \n924      0.999994      0.000009      0.999991 -0.000003       NaN       NaN   \n4483     0.662384      0.347477      0.652523  0.009861       NaN       NaN   \n6379     0.261170      0.742939      0.257061 -0.004109       NaN       NaN   \n4954     0.131011      0.880831      0.119169 -0.011842  0.051824 -0.063666   \n...           ...           ...           ...       ...       ...       ...   \n9117     0.456003      0.560840      0.439160  0.016844 -0.016364  0.033208   \n2490     0.328900      0.706714      0.293286 -0.035613 -0.035537 -0.000076   \n7908     0.424679      0.529842      0.470158 -0.045479 -0.040708 -0.004771   \n728           NaN           NaN           NaN  0.000000       NaN       NaN   \n6378          NaN           NaN           NaN  0.000000       NaN       NaN   \n\n      Season  \n8658    2016  \n924     2016  \n4483    2016  \n6379    2016  \n4954    2016  \n...      ...  \n9117    2016  \n2490    2016  \n7908    2016  \n728     2016  \n6378    2016  \n\n[6400 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8658</th>\n      <td>1</td>\n      <td>2017010104</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2221.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.034503</td>\n      <td>0.965497</td>\n      <td>0.036645</td>\n      <td>0.963355</td>\n      <td>-0.002142</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>924</th>\n      <td>2</td>\n      <td>2016121112</td>\n      <td>22</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>13</td>\n      <td>770.0</td>\n      <td>43.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000006</td>\n      <td>0.999994</td>\n      <td>0.000009</td>\n      <td>0.999991</td>\n      <td>-0.000003</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>4483</th>\n      <td>3</td>\n      <td>2016122400</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2971.0</td>\n      <td>29.0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.337616</td>\n      <td>0.662384</td>\n      <td>0.347477</td>\n      <td>0.652523</td>\n      <td>0.009861</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>6379</th>\n      <td>3</td>\n      <td>2016122409</td>\n      <td>13</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1813.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.738830</td>\n      <td>0.261170</td>\n      <td>0.742939</td>\n      <td>0.257061</td>\n      <td>-0.004109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>4954</th>\n      <td>3</td>\n      <td>2016122405</td>\n      <td>15</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1361.0</td>\n      <td>32.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>2.585387</td>\n      <td>-3.333391</td>\n      <td>0.868989</td>\n      <td>0.131011</td>\n      <td>0.880831</td>\n      <td>0.119169</td>\n      <td>-0.011842</td>\n      <td>0.051824</td>\n      <td>-0.063666</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9117</th>\n      <td>1</td>\n      <td>2017010112</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>263</td>\n      <td>15</td>\n      <td>3554.0</td>\n      <td>5.0</td>\n      <td>20</td>\n      <td>...</td>\n      <td>-0.544715</td>\n      <td>1.016787</td>\n      <td>0.543997</td>\n      <td>0.456003</td>\n      <td>0.560840</td>\n      <td>0.439160</td>\n      <td>0.016844</td>\n      <td>-0.016364</td>\n      <td>0.033208</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>2490</th>\n      <td>4</td>\n      <td>2016121805</td>\n      <td>21</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>478</td>\n      <td>6</td>\n      <td>352.0</td>\n      <td>8.0</td>\n      <td>24</td>\n      <td>...</td>\n      <td>-0.728169</td>\n      <td>-0.000420</td>\n      <td>0.671100</td>\n      <td>0.328900</td>\n      <td>0.706714</td>\n      <td>0.293286</td>\n      <td>-0.035613</td>\n      <td>-0.035537</td>\n      <td>-0.000076</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>7908</th>\n      <td>1</td>\n      <td>2017010108</td>\n      <td>27</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>803</td>\n      <td>5</td>\n      <td>-623.0</td>\n      <td>35.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.443135</td>\n      <td>-0.904967</td>\n      <td>0.575321</td>\n      <td>0.424679</td>\n      <td>0.529842</td>\n      <td>0.470158</td>\n      <td>-0.045479</td>\n      <td>-0.040708</td>\n      <td>-0.004771</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>728</th>\n      <td>2</td>\n      <td>2016121108</td>\n      <td>13</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>811</td>\n      <td>8</td>\n      <td>1333.0</td>\n      <td>39.0</td>\n      <td>27</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>6378</th>\n      <td>3</td>\n      <td>2016122409</td>\n      <td>13</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1813.0</td>\n      <td>14.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n  </tbody>\n</table>\n<p>6400 rows Ã— 95 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 8\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "x_train = encoder.fit_transform(x_train)\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "            Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n8658  2017-01-01  2017010104      7    2   1.0  07:01          8    2221.0   \n924   2016-12-11  2016121112     22    4   1.0  12:50         13     770.0   \n4483  2016-12-24  2016122400      5    1   2.0  04:31          5    2971.0   \n6379  2016-12-24  2016122409     13    2   4.0  00:13          1    1813.0   \n4954  2016-12-24  2016122405     15    3   1.0  07:41          8    1361.0   \n...          ...         ...    ...  ...   ...    ...        ...       ...   \n9117  2017-01-01  2017010112      1    1   1.0  14:14         15    3554.0   \n2490  2016-12-18  2016121805     21    4   2.0  05:52          6     352.0   \n7908  2017-01-01  2017010108     27    5   1.0  04:37          5    -623.0   \n728   2016-12-11  2016121108     13    3   NaN  07:13          8    1333.0   \n6378  2016-12-24  2016122409     13    2   NaN  00:13          1    1813.0   \n\n      PlayTimeDiff SideofField  ...    airEPA    yacEPA  Home_WP_pre  \\\n8658           9.0         MIA  ...       NaN       NaN     0.034503   \n924           43.0         ATL  ...       NaN       NaN     0.000006   \n4483          29.0         BUF  ...       NaN       NaN     0.337616   \n6379           0.0          SF  ...       NaN       NaN     0.738830   \n4954          32.0         TEN  ...  2.585387 -3.333391     0.868989   \n...            ...         ...  ...       ...       ...          ...   \n9117           5.0         DEN  ... -0.544715  1.016787     0.543997   \n2490           8.0          KC  ... -0.728169 -0.000420     0.671100   \n7908          35.0         CLE  ...  0.443135 -0.904967     0.575321   \n728           39.0          NO  ...       NaN       NaN          NaN   \n6378          14.0          SF  ...       NaN       NaN          NaN   \n\n      Away_WP_pre  Home_WP_post  Away_WP_post       WPA    airWPA    yacWPA  \\\n8658     0.965497      0.036645      0.963355 -0.002142       NaN       NaN   \n924      0.999994      0.000009      0.999991 -0.000003       NaN       NaN   \n4483     0.662384      0.347477      0.652523  0.009861       NaN       NaN   \n6379     0.261170      0.742939      0.257061 -0.004109       NaN       NaN   \n4954     0.131011      0.880831      0.119169 -0.011842  0.051824 -0.063666   \n...           ...           ...           ...       ...       ...       ...   \n9117     0.456003      0.560840      0.439160  0.016844 -0.016364  0.033208   \n2490     0.328900      0.706714      0.293286 -0.035613 -0.035537 -0.000076   \n7908     0.424679      0.529842      0.470158 -0.045479 -0.040708 -0.004771   \n728           NaN           NaN           NaN  0.000000       NaN       NaN   \n6378          NaN           NaN           NaN  0.000000       NaN       NaN   \n\n      Season  \n8658    2016  \n924     2016  \n4483    2016  \n6379    2016  \n4954    2016  \n...      ...  \n9117    2016  \n2490    2016  \n7908    2016  \n728     2016  \n6378    2016  \n\n[6400 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8658</th>\n      <td>2017-01-01</td>\n      <td>2017010104</td>\n      <td>7</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>07:01</td>\n      <td>8</td>\n      <td>2221.0</td>\n      <td>9.0</td>\n      <td>MIA</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.034503</td>\n      <td>0.965497</td>\n      <td>0.036645</td>\n      <td>0.963355</td>\n      <td>-0.002142</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>924</th>\n      <td>2016-12-11</td>\n      <td>2016121112</td>\n      <td>22</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>12:50</td>\n      <td>13</td>\n      <td>770.0</td>\n      <td>43.0</td>\n      <td>ATL</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000006</td>\n      <td>0.999994</td>\n      <td>0.000009</td>\n      <td>0.999991</td>\n      <td>-0.000003</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>4483</th>\n      <td>2016-12-24</td>\n      <td>2016122400</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>04:31</td>\n      <td>5</td>\n      <td>2971.0</td>\n      <td>29.0</td>\n      <td>BUF</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.337616</td>\n      <td>0.662384</td>\n      <td>0.347477</td>\n      <td>0.652523</td>\n      <td>0.009861</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>6379</th>\n      <td>2016-12-24</td>\n      <td>2016122409</td>\n      <td>13</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>00:13</td>\n      <td>1</td>\n      <td>1813.0</td>\n      <td>0.0</td>\n      <td>SF</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.738830</td>\n      <td>0.261170</td>\n      <td>0.742939</td>\n      <td>0.257061</td>\n      <td>-0.004109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>4954</th>\n      <td>2016-12-24</td>\n      <td>2016122405</td>\n      <td>15</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>07:41</td>\n      <td>8</td>\n      <td>1361.0</td>\n      <td>32.0</td>\n      <td>TEN</td>\n      <td>...</td>\n      <td>2.585387</td>\n      <td>-3.333391</td>\n      <td>0.868989</td>\n      <td>0.131011</td>\n      <td>0.880831</td>\n      <td>0.119169</td>\n      <td>-0.011842</td>\n      <td>0.051824</td>\n      <td>-0.063666</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9117</th>\n      <td>2017-01-01</td>\n      <td>2017010112</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14:14</td>\n      <td>15</td>\n      <td>3554.0</td>\n      <td>5.0</td>\n      <td>DEN</td>\n      <td>...</td>\n      <td>-0.544715</td>\n      <td>1.016787</td>\n      <td>0.543997</td>\n      <td>0.456003</td>\n      <td>0.560840</td>\n      <td>0.439160</td>\n      <td>0.016844</td>\n      <td>-0.016364</td>\n      <td>0.033208</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>2490</th>\n      <td>2016-12-18</td>\n      <td>2016121805</td>\n      <td>21</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>05:52</td>\n      <td>6</td>\n      <td>352.0</td>\n      <td>8.0</td>\n      <td>KC</td>\n      <td>...</td>\n      <td>-0.728169</td>\n      <td>-0.000420</td>\n      <td>0.671100</td>\n      <td>0.328900</td>\n      <td>0.706714</td>\n      <td>0.293286</td>\n      <td>-0.035613</td>\n      <td>-0.035537</td>\n      <td>-0.000076</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>7908</th>\n      <td>2017-01-01</td>\n      <td>2017010108</td>\n      <td>27</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>04:37</td>\n      <td>5</td>\n      <td>-623.0</td>\n      <td>35.0</td>\n      <td>CLE</td>\n      <td>...</td>\n      <td>0.443135</td>\n      <td>-0.904967</td>\n      <td>0.575321</td>\n      <td>0.424679</td>\n      <td>0.529842</td>\n      <td>0.470158</td>\n      <td>-0.045479</td>\n      <td>-0.040708</td>\n      <td>-0.004771</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>728</th>\n      <td>2016-12-11</td>\n      <td>2016121108</td>\n      <td>13</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>07:13</td>\n      <td>8</td>\n      <td>1333.0</td>\n      <td>39.0</td>\n      <td>NO</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n    <tr>\n      <th>6378</th>\n      <td>2016-12-24</td>\n      <td>2016122409</td>\n      <td>13</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>00:13</td>\n      <td>1</td>\n      <td>1813.0</td>\n      <td>14.0</td>\n      <td>SF</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016</td>\n    </tr>\n  </tbody>\n</table>\n<p>6400 rows Ã— 95 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.00000000e+00,  2.01701010e+09,  7.00000000e+00, ...,\n         1.55345352e-02, -9.21124963e-03,  2.01600000e+03],\n       [ 2.00000000e+00,  2.01612111e+09,  2.20000000e+01, ...,\n         1.55345352e-02, -9.21124963e-03,  2.01600000e+03],\n       [ 3.00000000e+00,  2.01612240e+09,  5.00000000e+00, ...,\n         1.55345352e-02, -9.21124963e-03,  2.01600000e+03],\n       ...,\n       [ 1.00000000e+00,  2.01701011e+09,  2.70000000e+01, ...,\n        -4.07077923e-02, -4.77083456e-03,  2.01600000e+03],\n       [ 2.00000000e+00,  2.01612111e+09,  1.30000000e+01, ...,\n         1.55345352e-02, -9.21124963e-03,  2.01600000e+03],\n       [ 3.00000000e+00,  2.01612241e+09,  1.30000000e+01, ...,\n         1.55345352e-02, -9.21124963e-03,  2.01600000e+03]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "x_train = imputer.fit_transform(x_train)\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}