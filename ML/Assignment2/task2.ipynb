{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.sgd import SGD\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score, Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment 2 in ML. Task 2\n",
    "### Ostapovich Oleg\n",
    "#### Section 1: Data Reading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize([32,32]),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.GTSRB(root='./data', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 2: Exploration and preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = dataset.__getitem__(0).__getitem__(0)\n",
    "img = img / 2 + 0.5\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "train_size, val_size, test_size = int(len(dataset)*0.7), int(len(dataset)*0.1), int(len(dataset)*0.2)\n",
    "train_dataset,val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 100\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "input_shape = dataset.__getitem__(0).__getitem__(0).numpy().shape\n",
    "print(input_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.1: Machine learning or Deep learning model defining, training and hyper-parameters turning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "            Conv2d-2           [-1, 32, 32, 32]           9,248\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,928\n",
      "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
      "            Conv2d-7            [-1, 128, 8, 8]          73,856\n",
      "            Conv2d-8            [-1, 128, 8, 8]         147,584\n",
      "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
      "          Flatten-10                 [-1, 2048]               0\n",
      "           Linear-11                  [-1, 512]       1,049,088\n",
      "           Linear-12                   [-1, 43]          22,059\n",
      "================================================================\n",
      "Total params: 1,358,155\n",
      "Trainable params: 1,358,155\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 5.18\n",
      "Estimated Total Size (MB): 6.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class StartModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StartModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3,padding=1),\n",
    "            nn.Conv2d(64, 64, 3,padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.Linear(512, 43))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "startmodel = StartModel().to(device)\n",
    "summary(startmodel, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "              ReLU-3           [-1, 32, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]           9,248\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "              ReLU-6           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 32, 16, 16]               0\n",
      "         Dropout2d-8           [-1, 32, 16, 16]               0\n",
      "            Conv2d-9           [-1, 64, 16, 16]          18,496\n",
      "      BatchNorm2d-10           [-1, 64, 16, 16]             128\n",
      "             ReLU-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,928\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-15             [-1, 64, 8, 8]               0\n",
      "        Dropout2d-16             [-1, 64, 8, 8]               0\n",
      "           Conv2d-17            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "             ReLU-19            [-1, 128, 8, 8]               0\n",
      "           Conv2d-20            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
      "             ReLU-22            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-23            [-1, 128, 4, 4]               0\n",
      "        Dropout2d-24            [-1, 128, 4, 4]               0\n",
      "          Flatten-25                 [-1, 2048]               0\n",
      "           Linear-26                  [-1, 512]       1,049,088\n",
      "      BatchNorm1d-27                  [-1, 512]           1,024\n",
      "          Dropout-28                  [-1, 512]               0\n",
      "             ReLU-29                  [-1, 512]               0\n",
      "           Linear-30                   [-1, 43]          22,059\n",
      "================================================================\n",
      "Total params: 1,360,075\n",
      "Trainable params: 1,360,075\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.88\n",
      "Params size (MB): 5.19\n",
      "Estimated Total Size (MB): 8.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32,32,3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(32,64,3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64,64,3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(64,128,3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128,128,3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,43))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "improvedmodel = ImprovedModel().to(device)\n",
    "summary(improvedmodel, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_evaluate(net, optimizer, writer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_func = Accuracy(num_classes=43, average='weighted').to(device)\n",
    "    f1_score_func = F1Score(num_classes=43, average='weighted').to(device)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        f1 = 0\n",
    "        accuracy = 0\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            accuracy += accuracy_func(pred, labels) * 100\n",
    "            f1 += f1_score_func(pred, labels) * 100\n",
    "\n",
    "        running_loss /= len(trainloader)\n",
    "        accuracy /= len(trainloader)\n",
    "        f1 /= len(trainloader)\n",
    "        writer.add_scalar('Training_Loss', running_loss, epoch)\n",
    "        writer.add_scalar('Training_Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Training_F1', f1, epoch)\n",
    "\n",
    "        print('Epoch {} - train loss:{}, accuracy:{}, f1_score:{}'.format(epoch+1, running_loss, accuracy, f1))\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0\n",
    "        val_f1_score = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += accuracy_func(pred, labels) * 100\n",
    "                val_f1_score += f1_score_func(pred, labels) * 100\n",
    "            val_loss /= len(valloader)\n",
    "            val_accuracy /= len(valloader)\n",
    "            val_f1_score /= len(valloader)\n",
    "            writer.add_scalar('Val_Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val_Accuracy', val_accuracy, epoch)\n",
    "            writer.add_scalar('Val_F1', val_f1_score, epoch)\n",
    "\n",
    "        print('Epoch {} - val loss:{}, accuracy:{}, f1_score:{}'.format(epoch+1, val_loss, val_accuracy, val_f1_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 4.1: Model performance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:3.7582443136058443, accuracy:4.268660545349121, f1_score:0.6849289536476135\n",
      "Epoch 1 - val loss:3.7552818684350875, accuracy:4.395604610443115, f1_score:0.659843921661377\n",
      "Epoch 2 - train loss:3.7527905375990147, accuracy:4.5551838874816895, f1_score:0.7434865236282349\n",
      "Epoch 2 - val loss:3.7500659284137545, accuracy:4.581616401672363, f1_score:0.6628457903862\n",
      "Epoch 3 - train loss:3.747281740789544, accuracy:4.641286849975586, f1_score:0.7538985013961792\n",
      "Epoch 3 - val loss:3.74482798576355, accuracy:4.630265712738037, f1_score:0.6736736297607422\n",
      "Epoch 4 - train loss:3.7415225669129253, accuracy:4.69382381439209, f1_score:0.7490038275718689\n",
      "Epoch 4 - val loss:3.7391048840114047, accuracy:4.544414043426514, f1_score:0.6756264567375183\n",
      "Epoch 5 - train loss:3.735279465374881, accuracy:4.657340049743652, f1_score:0.7271203398704529\n",
      "Epoch 5 - val loss:3.7328363827296664, accuracy:4.564445972442627, f1_score:0.6915250420570374\n",
      "Epoch 6 - train loss:3.72812682798464, accuracy:4.567345142364502, f1_score:0.7370671033859253\n",
      "Epoch 6 - val loss:3.725493487857637, accuracy:4.490041255950928, f1_score:0.676056444644928\n",
      "Epoch 7 - train loss:3.7195424625318343, accuracy:4.496809005737305, f1_score:0.7360578775405884\n",
      "Epoch 7 - val loss:3.7162282126290456, accuracy:4.452838897705078, f1_score:0.64238440990448\n",
      "Epoch 8 - train loss:3.7082672625371855, accuracy:4.46956729888916, f1_score:0.8421790599822998\n",
      "Epoch 8 - val loss:3.7036064011710033, accuracy:4.424221515655518, f1_score:0.8892067670822144\n",
      "Epoch 9 - train loss:3.6917734423728836, accuracy:5.224061965942383, f1_score:2.0136170387268066\n",
      "Epoch 9 - val loss:3.6840499469212125, accuracy:5.898008346557617, f1_score:2.764050006866455\n",
      "Epoch 10 - train loss:3.6643772353864694, accuracy:7.457873344421387, f1_score:3.497145891189575\n",
      "Epoch 10 - val loss:3.6494460787091936, accuracy:6.974015712738037, f1_score:2.800816059112549\n",
      "Epoch 11 - train loss:3.6145572221442444, accuracy:7.473926067352295, f1_score:2.867755651473999\n",
      "Epoch 11 - val loss:3.5899722576141357, accuracy:6.487522602081299, f1_score:2.4151101112365723\n",
      "Epoch 12 - train loss:3.5500517185420204, accuracy:6.922770023345947, f1_score:2.790658950805664\n",
      "Epoch 12 - val loss:3.5420334339141846, accuracy:6.023923873901367, f1_score:2.2615723609924316\n",
      "Epoch 13 - train loss:3.5178851771028072, accuracy:6.989414691925049, f1_score:3.035348892211914\n",
      "Epoch 13 - val loss:3.5266971474602107, accuracy:6.470353126525879, f1_score:2.984708547592163\n",
      "Epoch 14 - train loss:3.504931443358121, accuracy:7.518680095672607, f1_score:3.71819806098938\n",
      "Epoch 14 - val loss:3.516385634740194, accuracy:7.214400768280029, f1_score:3.8750686645507812\n",
      "Epoch 15 - train loss:3.4945047048673237, accuracy:7.9209794998168945, f1_score:4.224303245544434\n",
      "Epoch 15 - val loss:3.5050072897048223, accuracy:8.133012771606445, f1_score:4.843422889709473\n",
      "Epoch 16 - train loss:3.483246819613731, accuracy:8.57040023803711, f1_score:4.807243824005127\n",
      "Epoch 16 - val loss:3.4933629603612992, accuracy:8.47355842590332, f1_score:5.124047756195068\n",
      "Epoch 17 - train loss:3.4703451525675106, accuracy:9.34532642364502, f1_score:5.576786518096924\n",
      "Epoch 17 - val loss:3.4798948764801025, accuracy:9.068796157836914, f1_score:5.642180919647217\n",
      "Epoch 18 - train loss:3.4556276177706784, accuracy:9.892590522766113, f1_score:6.127170562744141\n",
      "Epoch 18 - val loss:3.4646650609515963, accuracy:9.64686393737793, f1_score:6.1605448722839355\n",
      "Epoch 19 - train loss:3.436301344061551, accuracy:10.570711135864258, f1_score:6.669434070587158\n",
      "Epoch 19 - val loss:3.443155606587728, accuracy:10.316506385803223, f1_score:6.794888019561768\n",
      "Epoch 20 - train loss:3.4126708817808598, accuracy:10.876206398010254, f1_score:6.885690689086914\n",
      "Epoch 20 - val loss:3.4197336037953696, accuracy:11.904762268066406, f1_score:8.084147453308105\n"
     ]
    }
   ],
   "source": [
    "# model without improving\n",
    "optimizer = torch.optim.SGD(startmodel.parameters(), lr=learning_rate)\n",
    "writer = SummaryWriter('runs/BaseModel')\n",
    "train_evaluate(startmodel, optimizer, writer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:3.714235869172501, accuracy:5.285355567932129, f1_score:4.455452919006348\n",
      "Epoch 1 - val loss:3.631051880972726, accuracy:7.366071701049805, f1_score:5.5320143699646\n",
      "Epoch 2 - train loss:3.5578197044868993, accuracy:8.185126304626465, f1_score:5.916228771209717\n",
      "Epoch 2 - val loss:3.507082473664057, accuracy:9.32348918914795, f1_score:6.940835952758789\n",
      "Epoch 3 - train loss:3.45314037309934, accuracy:9.927128791809082, f1_score:7.262463569641113\n",
      "Epoch 3 - val loss:3.4246347972324918, accuracy:10.75148868560791, f1_score:7.797257900238037\n",
      "Epoch 4 - train loss:3.3760843325967658, accuracy:12.060242652893066, f1_score:9.08124828338623\n",
      "Epoch 4 - val loss:3.351353656677973, accuracy:12.276785850524902, f1_score:9.03854751586914\n",
      "Epoch 5 - train loss:3.3037756518141865, accuracy:13.666037559509277, f1_score:10.38022232055664\n",
      "Epoch 5 - val loss:3.2881591660635814, accuracy:13.570283889770508, f1_score:10.465517044067383\n",
      "Epoch 6 - train loss:3.236494681606554, accuracy:15.56711196899414, f1_score:12.117706298828125\n",
      "Epoch 6 - val loss:3.22637753259568, accuracy:16.085737228393555, f1_score:12.503750801086426\n",
      "Epoch 7 - train loss:3.161976696693734, accuracy:17.915239334106445, f1_score:14.293734550476074\n",
      "Epoch 7 - val loss:3.155239672887893, accuracy:17.791324615478516, f1_score:13.966025352478027\n",
      "Epoch 8 - train loss:3.0923960110912585, accuracy:20.461355209350586, f1_score:16.40481185913086\n",
      "Epoch 8 - val loss:3.0792839186532155, accuracy:19.51694107055664, f1_score:15.569738388061523\n",
      "Epoch 9 - train loss:3.020767821024542, accuracy:21.951860427856445, f1_score:17.5462703704834\n",
      "Epoch 9 - val loss:3.011466173898606, accuracy:23.139881134033203, f1_score:18.440011978149414\n",
      "Epoch 10 - train loss:2.941584923495985, accuracy:24.499921798706055, f1_score:19.76864242553711\n",
      "Epoch 10 - val loss:2.935593389329456, accuracy:23.70077896118164, f1_score:19.122133255004883\n",
      "Epoch 11 - train loss:2.8636307438758957, accuracy:26.31683921813965, f1_score:21.26505470275879\n",
      "Epoch 11 - val loss:2.8538983435857865, accuracy:25.789836883544922, f1_score:20.601276397705078\n",
      "Epoch 12 - train loss:2.789570256455304, accuracy:27.841394424438477, f1_score:22.52398109436035\n",
      "Epoch 12 - val loss:2.769167252949306, accuracy:27.415292739868164, f1_score:21.935733795166016\n",
      "Epoch 13 - train loss:2.706043968461964, accuracy:29.11591339111328, f1_score:23.422046661376953\n",
      "Epoch 13 - val loss:2.7090111800602505, accuracy:29.395605087280273, f1_score:23.739818572998047\n",
      "Epoch 14 - train loss:2.627981043841741, accuracy:31.0889835357666, f1_score:25.367876052856445\n",
      "Epoch 14 - val loss:2.642131249109904, accuracy:30.302770614624023, f1_score:24.64000129699707\n",
      "Epoch 15 - train loss:2.5580904483795166, accuracy:32.26815414428711, f1_score:26.47740936279297\n",
      "Epoch 15 - val loss:2.563063553401402, accuracy:31.041093826293945, f1_score:24.934980392456055\n",
      "Epoch 16 - train loss:2.4878866754166067, accuracy:33.54461669921875, f1_score:27.60922622680664\n",
      "Epoch 16 - val loss:2.4856253124418712, accuracy:34.678340911865234, f1_score:28.30269432067871\n",
      "Epoch 17 - train loss:2.416320902027496, accuracy:35.12852096557617, f1_score:29.03683853149414\n",
      "Epoch 17 - val loss:2.4314523537953696, accuracy:33.58802795410156, f1_score:27.411760330200195\n",
      "Epoch 18 - train loss:2.349534029829992, accuracy:36.70658874511719, f1_score:30.52783203125\n",
      "Epoch 18 - val loss:2.3508916809445335, accuracy:36.515567779541016, f1_score:29.960742950439453\n",
      "Epoch 19 - train loss:2.2881692288673086, accuracy:37.7568473815918, f1_score:31.593088150024414\n",
      "Epoch 19 - val loss:2.283152761913481, accuracy:37.83482360839844, f1_score:31.882476806640625\n",
      "Epoch 20 - train loss:2.2275604858790357, accuracy:38.662147521972656, f1_score:32.62677764892578\n",
      "Epoch 20 - val loss:2.235435656138829, accuracy:38.5531120300293, f1_score:32.692996978759766\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(improvedmodel.parameters(), lr=learning_rate)\n",
    "writer2 = SummaryWriter('runs/ImprovedModel')\n",
    "train_evaluate(improvedmodel, optimizer, writer2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task2.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.2: Machine learning or Deep learning model defining, training and hyper-parameters turning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 43]          22,059\n",
      "           ResNet-69                   [-1, 43]               0\n",
      "================================================================\n",
      "Total params: 11,198,571\n",
      "Trainable params: 11,198,571\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 42.72\n",
      "Estimated Total Size (MB): 44.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = models.resnet18()\n",
    "        self.net.trainable = False # Freeze the layers of the pretrained model\n",
    "        self.net.fc = nn.Linear(512, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "shuff = Net().to(device)\n",
    "summary(shuff, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 16, 16]             648\n",
      "       BatchNorm2d-2           [-1, 24, 16, 16]              48\n",
      "              ReLU-3           [-1, 24, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 24, 8, 8]               0\n",
      "            Conv2d-5             [-1, 24, 4, 4]             216\n",
      "       BatchNorm2d-6             [-1, 24, 4, 4]              48\n",
      "            Conv2d-7             [-1, 88, 4, 4]           2,112\n",
      "       BatchNorm2d-8             [-1, 88, 4, 4]             176\n",
      "              ReLU-9             [-1, 88, 4, 4]               0\n",
      "           Conv2d-10             [-1, 88, 8, 8]           2,112\n",
      "      BatchNorm2d-11             [-1, 88, 8, 8]             176\n",
      "             ReLU-12             [-1, 88, 8, 8]               0\n",
      "           Conv2d-13             [-1, 88, 4, 4]             792\n",
      "      BatchNorm2d-14             [-1, 88, 4, 4]             176\n",
      "           Conv2d-15             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-16             [-1, 88, 4, 4]             176\n",
      "             ReLU-17             [-1, 88, 4, 4]               0\n",
      " InvertedResidual-18            [-1, 176, 4, 4]               0\n",
      "           Conv2d-19             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-20             [-1, 88, 4, 4]             176\n",
      "             ReLU-21             [-1, 88, 4, 4]               0\n",
      "           Conv2d-22             [-1, 88, 4, 4]             792\n",
      "      BatchNorm2d-23             [-1, 88, 4, 4]             176\n",
      "           Conv2d-24             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-25             [-1, 88, 4, 4]             176\n",
      "             ReLU-26             [-1, 88, 4, 4]               0\n",
      " InvertedResidual-27            [-1, 176, 4, 4]               0\n",
      "           Conv2d-28             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-29             [-1, 88, 4, 4]             176\n",
      "             ReLU-30             [-1, 88, 4, 4]               0\n",
      "           Conv2d-31             [-1, 88, 4, 4]             792\n",
      "      BatchNorm2d-32             [-1, 88, 4, 4]             176\n",
      "           Conv2d-33             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-34             [-1, 88, 4, 4]             176\n",
      "             ReLU-35             [-1, 88, 4, 4]               0\n",
      " InvertedResidual-36            [-1, 176, 4, 4]               0\n",
      "           Conv2d-37             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-38             [-1, 88, 4, 4]             176\n",
      "             ReLU-39             [-1, 88, 4, 4]               0\n",
      "           Conv2d-40             [-1, 88, 4, 4]             792\n",
      "      BatchNorm2d-41             [-1, 88, 4, 4]             176\n",
      "           Conv2d-42             [-1, 88, 4, 4]           7,744\n",
      "      BatchNorm2d-43             [-1, 88, 4, 4]             176\n",
      "             ReLU-44             [-1, 88, 4, 4]               0\n",
      " InvertedResidual-45            [-1, 176, 4, 4]               0\n",
      "           Conv2d-46            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-47            [-1, 176, 2, 2]             352\n",
      "           Conv2d-48            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-49            [-1, 176, 2, 2]             352\n",
      "             ReLU-50            [-1, 176, 2, 2]               0\n",
      "           Conv2d-51            [-1, 176, 4, 4]          30,976\n",
      "      BatchNorm2d-52            [-1, 176, 4, 4]             352\n",
      "             ReLU-53            [-1, 176, 4, 4]               0\n",
      "           Conv2d-54            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-55            [-1, 176, 2, 2]             352\n",
      "           Conv2d-56            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-57            [-1, 176, 2, 2]             352\n",
      "             ReLU-58            [-1, 176, 2, 2]               0\n",
      " InvertedResidual-59            [-1, 352, 2, 2]               0\n",
      "           Conv2d-60            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-61            [-1, 176, 2, 2]             352\n",
      "             ReLU-62            [-1, 176, 2, 2]               0\n",
      "           Conv2d-63            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-64            [-1, 176, 2, 2]             352\n",
      "           Conv2d-65            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-66            [-1, 176, 2, 2]             352\n",
      "             ReLU-67            [-1, 176, 2, 2]               0\n",
      " InvertedResidual-68            [-1, 352, 2, 2]               0\n",
      "           Conv2d-69            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-70            [-1, 176, 2, 2]             352\n",
      "             ReLU-71            [-1, 176, 2, 2]               0\n",
      "           Conv2d-72            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-73            [-1, 176, 2, 2]             352\n",
      "           Conv2d-74            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-75            [-1, 176, 2, 2]             352\n",
      "             ReLU-76            [-1, 176, 2, 2]               0\n",
      " InvertedResidual-77            [-1, 352, 2, 2]               0\n",
      "           Conv2d-78            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-79            [-1, 176, 2, 2]             352\n",
      "             ReLU-80            [-1, 176, 2, 2]               0\n",
      "           Conv2d-81            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-82            [-1, 176, 2, 2]             352\n",
      "           Conv2d-83            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-84            [-1, 176, 2, 2]             352\n",
      "             ReLU-85            [-1, 176, 2, 2]               0\n",
      " InvertedResidual-86            [-1, 352, 2, 2]               0\n",
      "           Conv2d-87            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-88            [-1, 176, 2, 2]             352\n",
      "             ReLU-89            [-1, 176, 2, 2]               0\n",
      "           Conv2d-90            [-1, 176, 2, 2]           1,584\n",
      "      BatchNorm2d-91            [-1, 176, 2, 2]             352\n",
      "           Conv2d-92            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-93            [-1, 176, 2, 2]             352\n",
      "             ReLU-94            [-1, 176, 2, 2]               0\n",
      " InvertedResidual-95            [-1, 352, 2, 2]               0\n",
      "           Conv2d-96            [-1, 176, 2, 2]          30,976\n",
      "      BatchNorm2d-97            [-1, 176, 2, 2]             352\n",
      "             ReLU-98            [-1, 176, 2, 2]               0\n",
      "           Conv2d-99            [-1, 176, 2, 2]           1,584\n",
      "     BatchNorm2d-100            [-1, 176, 2, 2]             352\n",
      "          Conv2d-101            [-1, 176, 2, 2]          30,976\n",
      "     BatchNorm2d-102            [-1, 176, 2, 2]             352\n",
      "            ReLU-103            [-1, 176, 2, 2]               0\n",
      "InvertedResidual-104            [-1, 352, 2, 2]               0\n",
      "          Conv2d-105            [-1, 176, 2, 2]          30,976\n",
      "     BatchNorm2d-106            [-1, 176, 2, 2]             352\n",
      "            ReLU-107            [-1, 176, 2, 2]               0\n",
      "          Conv2d-108            [-1, 176, 2, 2]           1,584\n",
      "     BatchNorm2d-109            [-1, 176, 2, 2]             352\n",
      "          Conv2d-110            [-1, 176, 2, 2]          30,976\n",
      "     BatchNorm2d-111            [-1, 176, 2, 2]             352\n",
      "            ReLU-112            [-1, 176, 2, 2]               0\n",
      "InvertedResidual-113            [-1, 352, 2, 2]               0\n",
      "          Conv2d-114            [-1, 176, 2, 2]          30,976\n",
      "     BatchNorm2d-115            [-1, 176, 2, 2]             352\n",
      "            ReLU-116            [-1, 176, 2, 2]               0\n",
      "          Conv2d-117            [-1, 176, 2, 2]           1,584\n",
      "     BatchNorm2d-118            [-1, 176, 2, 2]             352\n",
      "          Conv2d-119            [-1, 176, 2, 2]          30,976\n",
      "     BatchNorm2d-120            [-1, 176, 2, 2]             352\n",
      "            ReLU-121            [-1, 176, 2, 2]               0\n",
      "InvertedResidual-122            [-1, 352, 2, 2]               0\n",
      "          Conv2d-123            [-1, 352, 1, 1]           3,168\n",
      "     BatchNorm2d-124            [-1, 352, 1, 1]             704\n",
      "          Conv2d-125            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-126            [-1, 352, 1, 1]             704\n",
      "            ReLU-127            [-1, 352, 1, 1]               0\n",
      "          Conv2d-128            [-1, 352, 2, 2]         123,904\n",
      "     BatchNorm2d-129            [-1, 352, 2, 2]             704\n",
      "            ReLU-130            [-1, 352, 2, 2]               0\n",
      "          Conv2d-131            [-1, 352, 1, 1]           3,168\n",
      "     BatchNorm2d-132            [-1, 352, 1, 1]             704\n",
      "          Conv2d-133            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-134            [-1, 352, 1, 1]             704\n",
      "            ReLU-135            [-1, 352, 1, 1]               0\n",
      "InvertedResidual-136            [-1, 704, 1, 1]               0\n",
      "          Conv2d-137            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-138            [-1, 352, 1, 1]             704\n",
      "            ReLU-139            [-1, 352, 1, 1]               0\n",
      "          Conv2d-140            [-1, 352, 1, 1]           3,168\n",
      "     BatchNorm2d-141            [-1, 352, 1, 1]             704\n",
      "          Conv2d-142            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-143            [-1, 352, 1, 1]             704\n",
      "            ReLU-144            [-1, 352, 1, 1]               0\n",
      "InvertedResidual-145            [-1, 704, 1, 1]               0\n",
      "          Conv2d-146            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-147            [-1, 352, 1, 1]             704\n",
      "            ReLU-148            [-1, 352, 1, 1]               0\n",
      "          Conv2d-149            [-1, 352, 1, 1]           3,168\n",
      "     BatchNorm2d-150            [-1, 352, 1, 1]             704\n",
      "          Conv2d-151            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-152            [-1, 352, 1, 1]             704\n",
      "            ReLU-153            [-1, 352, 1, 1]               0\n",
      "InvertedResidual-154            [-1, 704, 1, 1]               0\n",
      "          Conv2d-155            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-156            [-1, 352, 1, 1]             704\n",
      "            ReLU-157            [-1, 352, 1, 1]               0\n",
      "          Conv2d-158            [-1, 352, 1, 1]           3,168\n",
      "     BatchNorm2d-159            [-1, 352, 1, 1]             704\n",
      "          Conv2d-160            [-1, 352, 1, 1]         123,904\n",
      "     BatchNorm2d-161            [-1, 352, 1, 1]             704\n",
      "            ReLU-162            [-1, 352, 1, 1]               0\n",
      "InvertedResidual-163            [-1, 704, 1, 1]               0\n",
      "        Identity-164            [-1, 704, 1, 1]               0\n",
      "          Linear-165                   [-1, 43]          30,315\n",
      "    ShuffleNetV2-166                   [-1, 43]               0\n",
      "================================================================\n",
      "Total params: 1,785,995\n",
      "Trainable params: 1,785,995\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.37\n",
      "Params size (MB): 6.81\n",
      "Estimated Total Size (MB): 8.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class NetReduced(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetReduced, self).__init__()\n",
    "        self.net = models.shufflenet_v2_x1_5()\n",
    "        self.net.trainable = False # Freeze the layers of the pretrained model\n",
    "        self.net.conv5 = Identity()\n",
    "        self.net.fc = nn.Linear(704, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "shuffreduced = NetReduced().to(device)\n",
    "summary(shuffreduced, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 4.2: Model performance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:3.530795855064915, accuracy:10.454448699951172, f1_score:8.674538612365723\n",
      "Epoch 1 - val loss:3.1678708507901145, accuracy:19.79452896118164, f1_score:16.97509765625\n",
      "Epoch 2 - train loss:2.930984519932368, accuracy:25.883405685424805, f1_score:22.107994079589844\n",
      "Epoch 2 - val loss:2.7444336187271845, accuracy:31.169872283935547, f1_score:27.11604881286621\n",
      "Epoch 3 - train loss:2.55049563434026, accuracy:35.7779426574707, f1_score:31.47150230407715\n",
      "Epoch 3 - val loss:2.430770306360154, accuracy:39.631980895996094, f1_score:35.63232421875\n",
      "Epoch 4 - train loss:2.2400659935115135, accuracy:45.12424087524414, f1_score:40.99833679199219\n",
      "Epoch 4 - val loss:2.153460729689825, accuracy:47.28136444091797, f1_score:43.31380844116211\n",
      "Epoch 5 - train loss:1.9634428391717884, accuracy:53.386226654052734, f1_score:49.334327697753906\n",
      "Epoch 5 - val loss:1.9338504870732625, accuracy:51.917354583740234, f1_score:48.22197723388672\n",
      "Epoch 6 - train loss:1.7352579358505875, accuracy:58.758174896240234, f1_score:55.119232177734375\n",
      "Epoch 6 - val loss:1.721691375687009, accuracy:58.12443161010742, f1_score:54.663047790527344\n",
      "Epoch 7 - train loss:1.5375227666880986, accuracy:63.523014068603516, f1_score:60.20854187011719\n",
      "Epoch 7 - val loss:1.5543877964928037, accuracy:62.17376708984375, f1_score:59.3237190246582\n",
      "Epoch 8 - train loss:1.3666418447886428, accuracy:67.97312927246094, f1_score:65.04474639892578\n",
      "Epoch 8 - val loss:1.414712735584804, accuracy:65.49908447265625, f1_score:63.02464294433594\n",
      "Epoch 9 - train loss:1.2206075550758675, accuracy:71.95477294921875, f1_score:69.47844696044922\n",
      "Epoch 9 - val loss:1.2967236496153332, accuracy:68.0088119506836, f1_score:65.82665252685547\n",
      "Epoch 10 - train loss:1.0955665711670706, accuracy:75.6124496459961, f1_score:73.56941986083984\n",
      "Epoch 10 - val loss:1.1862061591375441, accuracy:71.52301025390625, f1_score:69.55470275878906\n",
      "Epoch 11 - train loss:0.9879926590070333, accuracy:78.18531799316406, f1_score:76.39204406738281\n",
      "Epoch 11 - val loss:1.0892795806839353, accuracy:73.57486724853516, f1_score:71.78087615966797\n",
      "Epoch 12 - train loss:0.8836445698182877, accuracy:81.22762298583984, f1_score:79.7878189086914\n",
      "Epoch 12 - val loss:1.0042992915425981, accuracy:76.69413757324219, f1_score:75.03102111816406\n",
      "Epoch 13 - train loss:0.803051085096516, accuracy:83.0776138305664, f1_score:81.86844635009766\n",
      "Epoch 13 - val loss:0.9232816043354216, accuracy:78.52564239501953, f1_score:77.37535095214844\n",
      "Epoch 14 - train loss:0.718249111551128, accuracy:85.73464965820312, f1_score:84.57330322265625\n",
      "Epoch 14 - val loss:0.858135271640051, accuracy:79.68463897705078, f1_score:78.35713195800781\n",
      "Epoch 15 - train loss:0.6458989469564125, accuracy:87.68582916259766, f1_score:86.67009735107422\n",
      "Epoch 15 - val loss:0.8008482257525126, accuracy:81.17273712158203, f1_score:80.22411346435547\n",
      "Epoch 16 - train loss:0.5871132453010507, accuracy:89.09022521972656, f1_score:88.32511138916016\n",
      "Epoch 16 - val loss:0.7497747512090773, accuracy:82.91838073730469, f1_score:82.0027084350586\n",
      "Epoch 17 - train loss:0.5327076442437629, accuracy:90.63180541992188, f1_score:89.93946075439453\n",
      "Epoch 17 - val loss:0.7045676708221436, accuracy:84.70409393310547, f1_score:84.17767333984375\n",
      "Epoch 18 - train loss:0.484073133093037, accuracy:91.49916076660156, f1_score:90.88565826416016\n",
      "Epoch 18 - val loss:0.6554311343601772, accuracy:85.7514877319336, f1_score:85.18818664550781\n",
      "Epoch 19 - train loss:0.4406051360172768, accuracy:92.95658874511719, f1_score:92.48455810546875\n",
      "Epoch 19 - val loss:0.6160611680575779, accuracy:85.88885498046875, f1_score:85.16259002685547\n",
      "Epoch 20 - train loss:0.40486171576258256, accuracy:93.5938491821289, f1_score:93.1688003540039\n",
      "Epoch 20 - val loss:0.5782759487628937, accuracy:87.57726287841797, f1_score:87.14837646484375\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(shuff.parameters(),lr=learning_rate)\n",
    "writer3 = SummaryWriter('runs/TLmodel')\n",
    "train_evaluate(shuff, optimizer, writer3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:3.7283972648725117, accuracy:4.090130805969238, f1_score:3.603311061859131\n",
      "Epoch 1 - val loss:3.658048255102975, accuracy:5.40865421295166, f1_score:4.173295021057129\n",
      "Epoch 2 - train loss:3.5928740844334643, accuracy:6.614356517791748, f1_score:5.0245137214660645\n",
      "Epoch 2 - val loss:3.566355376016526, accuracy:6.616300582885742, f1_score:5.01871919631958\n",
      "Epoch 3 - train loss:3.5160380667203093, accuracy:7.818824291229248, f1_score:5.703953742980957\n",
      "Epoch 3 - val loss:3.517203137988136, accuracy:7.26591157913208, f1_score:5.1585612297058105\n",
      "Epoch 4 - train loss:3.473716384743991, accuracy:8.59375, f1_score:6.263426303863525\n",
      "Epoch 4 - val loss:3.4733046690622964, accuracy:8.688186645507812, f1_score:6.381995677947998\n",
      "Epoch 5 - train loss:3.428969357111683, accuracy:9.904265403747559, f1_score:7.166472911834717\n",
      "Epoch 5 - val loss:3.443641878309704, accuracy:9.858631134033203, f1_score:6.768109321594238\n",
      "Epoch 6 - train loss:3.385286269122607, accuracy:11.438064575195312, f1_score:8.34172534942627\n",
      "Epoch 6 - val loss:3.3915338856833324, accuracy:10.8630952835083, f1_score:7.857115268707275\n",
      "Epoch 7 - train loss:3.3454669550673604, accuracy:12.603128433227539, f1_score:9.08505916595459\n",
      "Epoch 7 - val loss:3.3567976383935836, accuracy:11.521291732788086, f1_score:8.206395149230957\n",
      "Epoch 8 - train loss:3.3037287715363175, accuracy:13.905374526977539, f1_score:10.36052417755127\n",
      "Epoch 8 - val loss:3.3268598715464273, accuracy:13.166781425476074, f1_score:9.746597290039062\n",
      "Epoch 9 - train loss:3.26079561449077, accuracy:15.179891586303711, f1_score:11.305078506469727\n",
      "Epoch 9 - val loss:3.2609028135027205, accuracy:15.710851669311523, f1_score:11.876086235046387\n",
      "Epoch 10 - train loss:3.1885882256782216, accuracy:17.581043243408203, f1_score:13.278728485107422\n",
      "Epoch 10 - val loss:3.201982237043835, accuracy:16.514995574951172, f1_score:12.437151908874512\n",
      "Epoch 11 - train loss:3.1107615069167256, accuracy:20.05808448791504, f1_score:15.31273365020752\n",
      "Epoch 11 - val loss:3.11881076721918, accuracy:19.330930709838867, f1_score:14.80239486694336\n",
      "Epoch 12 - train loss:3.020010827338859, accuracy:22.773971557617188, f1_score:17.701160430908203\n",
      "Epoch 12 - val loss:3.0448640755244663, accuracy:21.23111343383789, f1_score:16.488025665283203\n",
      "Epoch 13 - train loss:2.933418765459975, accuracy:25.125507354736328, f1_score:19.920940399169922\n",
      "Epoch 13 - val loss:2.9509236131395613, accuracy:25.062959671020508, f1_score:19.58344078063965\n",
      "Epoch 14 - train loss:2.8351226996069085, accuracy:27.404558181762695, f1_score:21.959026336669922\n",
      "Epoch 14 - val loss:2.8658047290075395, accuracy:26.903045654296875, f1_score:20.929567337036133\n",
      "Epoch 15 - train loss:2.7403870772009027, accuracy:29.81057357788086, f1_score:24.27739143371582\n",
      "Epoch 15 - val loss:2.783229566755749, accuracy:28.010530471801758, f1_score:22.55461311340332\n",
      "Epoch 16 - train loss:2.644047822037788, accuracy:32.17378234863281, f1_score:26.75031852722168\n",
      "Epoch 16 - val loss:2.678825957434518, accuracy:30.64904022216797, f1_score:24.924095153808594\n",
      "Epoch 17 - train loss:2.5455289425915235, accuracy:34.74665069580078, f1_score:29.162851333618164\n",
      "Epoch 17 - val loss:2.5871650718507313, accuracy:32.411861419677734, f1_score:27.07262420654297\n",
      "Epoch 18 - train loss:2.447905279185674, accuracy:36.87052536010742, f1_score:31.497901916503906\n",
      "Epoch 18 - val loss:2.4965623901003884, accuracy:34.071659088134766, f1_score:29.176708221435547\n",
      "Epoch 19 - train loss:2.3517819038809162, accuracy:39.446800231933594, f1_score:34.31730651855469\n",
      "Epoch 19 - val loss:2.421013729912894, accuracy:36.24656677246094, f1_score:31.008522033691406\n",
      "Epoch 20 - train loss:2.2615300376121312, accuracy:41.71758270263672, f1_score:36.56013107299805\n",
      "Epoch 20 - val loss:2.343022653034755, accuracy:36.87328338623047, f1_score:32.23983383178711\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(shuffreduced.parameters(),lr=learning_rate)\n",
    "writer4 = SummaryWriter('runs/TLmodelReduced')\n",
    "train_evaluate(shuffreduced, optimizer, writer4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 5: Conclusion and possible improvements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}