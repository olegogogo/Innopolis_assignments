{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.sgd import SGD\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "import time"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "prBxqOqDICdZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F48qgyjpICdc",
    "outputId": "2467316e-0763-4d67-cf72-8008edccfc7b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment 2 in ML. Task 2\n",
    "### Ostapovich Oleg\n",
    "#### Section 1: Data Reading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fv11lxraICdd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rq7gP9qgICde"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Custom MinMaxScaler\n",
    "class MinMaxScaler():\n",
    "    def __call__(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        dist = (tensor.max(dim=1, keepdim=True)[0] - tensor.min(dim=1, keepdim=True)[0])\n",
    "        dist[dist==0.] = 1.\n",
    "        scale = 1.0 /  dist\n",
    "        tensor.mul_(scale).sub_(tensor.min(dim=1, keepdim=True)[0])\n",
    "        return tensor"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "As0Hd2EZICdf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "H5Bdc1dpICdf"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize([32,32]),\n",
    "     # MinMaxScaler()\n",
    "     ])\n",
    "\n",
    "dataset = torchvision.datasets.GTSRB(root='./data', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2100)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code shows that data was scaled\n",
    "dataset.__getitem__(0)[0].min()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWMHo2QxICdg",
    "outputId": "4c94aeec-a846-45f0-ff89-28ad500e360d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 2: Exploration and preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "kXphYxr1ICdg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = dataset.__getitem__(0).__getitem__(0)\n",
    "img = img / 2 + 0.5\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "EGByXJyWICdh",
    "outputId": "e9be7ac0-089b-4664-8045-624572735651"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Data splitting\n",
    "train_size, val_size, test_size = int(len(dataset)*0.7), int(len(dataset)*0.1), int(len(dataset)*0.2)\n",
    "train_dataset,val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "63gabDGrICdh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 100\n",
    "# Adding data to loader\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rcg9fLv2ICdi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.1: Machine learning or Deep learning model defining, training and hyper-parameters turning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ZZWIjpfhICdi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "            Conv2d-2           [-1, 32, 32, 32]           9,248\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,928\n",
      "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
      "            Conv2d-7            [-1, 128, 8, 8]          73,856\n",
      "            Conv2d-8            [-1, 128, 8, 8]         147,584\n",
      "         MaxPool2d-9            [-1, 128, 4, 4]               0\n",
      "          Flatten-10                 [-1, 2048]               0\n",
      "           Linear-11                  [-1, 512]       1,049,088\n",
      "           Linear-12                   [-1, 43]          22,059\n",
      "================================================================\n",
      "Total params: 1,358,155\n",
      "Trainable params: 1,358,155\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 5.18\n",
      "Estimated Total Size (MB): 6.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class StartModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StartModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3,padding=1),\n",
    "            nn.Conv2d(64, 64, 3,padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.Linear(512, 43))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "startmodel = StartModel().to(device)\n",
    "summary(startmodel, (3, 32, 32))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOsGAR5aICdi",
    "outputId": "770b9a2c-dd42-433d-91dc-45e689126c41"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "         Dropout2d-2           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
      "              ReLU-4           [-1, 32, 32, 32]               0\n",
      "            Conv2d-5           [-1, 32, 32, 32]           9,248\n",
      "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
      "              ReLU-7           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-8           [-1, 32, 16, 16]               0\n",
      "         Dropout2d-9           [-1, 32, 16, 16]               0\n",
      "           Conv2d-10           [-1, 64, 16, 16]          18,496\n",
      "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
      "             ReLU-12           [-1, 64, 16, 16]               0\n",
      "           Conv2d-13           [-1, 64, 16, 16]          36,928\n",
      "      BatchNorm2d-14           [-1, 64, 16, 16]             128\n",
      "             ReLU-15           [-1, 64, 16, 16]               0\n",
      "        MaxPool2d-16             [-1, 64, 8, 8]               0\n",
      "        Dropout2d-17             [-1, 64, 8, 8]               0\n",
      "           Conv2d-18            [-1, 128, 8, 8]          73,856\n",
      "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
      "             ReLU-20            [-1, 128, 8, 8]               0\n",
      "           Conv2d-21            [-1, 128, 8, 8]         147,584\n",
      "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
      "             ReLU-23            [-1, 128, 8, 8]               0\n",
      "        MaxPool2d-24            [-1, 128, 4, 4]               0\n",
      "        Dropout2d-25            [-1, 128, 4, 4]               0\n",
      "          Flatten-26                 [-1, 2048]               0\n",
      "           Linear-27                  [-1, 512]       1,049,088\n",
      "      BatchNorm1d-28                  [-1, 512]           1,024\n",
      "          Dropout-29                  [-1, 512]               0\n",
      "             ReLU-30                  [-1, 512]               0\n",
      "           Linear-31                   [-1, 43]          22,059\n",
      "================================================================\n",
      "Total params: 1,360,075\n",
      "Trainable params: 1,360,075\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.13\n",
      "Params size (MB): 5.19\n",
      "Estimated Total Size (MB): 8.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ImprovedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedModel, self).__init__()\n",
    "        self.network=nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32,32,3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(32,64,3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64,64,3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Conv2d(64,128,3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128,128,3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,43))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "improvedmodel = ImprovedModel().to(device)\n",
    "summary(improvedmodel, (3, 32, 32))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO20bLgZICdj",
    "outputId": "bc91f41c-1bb9-4992-b727-11e86c1f96d1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_evaluate(net, optimizer, writer):\n",
    "    starttime = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_func = Accuracy(num_classes=43, average='weighted').to(device)\n",
    "    f1_score_func = F1Score(num_classes=43, average='weighted').to(device)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        f1 = 0\n",
    "        accuracy = 0\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            accuracy += accuracy_func(pred, labels) * 100\n",
    "            f1 += f1_score_func(pred, labels) * 100\n",
    "\n",
    "        running_loss /= len(trainloader)\n",
    "        accuracy /= len(trainloader)\n",
    "        f1 /= len(trainloader)\n",
    "        writer.add_scalar('Training_Loss', running_loss, epoch)\n",
    "        writer.add_scalar('Training_Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Training_F1', f1, epoch)\n",
    "\n",
    "        print('Epoch {} - train loss:{}, accuracy:{}, f1_score:{}, time passed {}s'.format(epoch+1, running_loss, accuracy, f1, int(time.time()-starttime)))\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0\n",
    "        val_f1_score = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, pred = torch.max(outputs.data, 1)\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += accuracy_func(pred, labels) * 100\n",
    "                val_f1_score += f1_score_func(pred, labels) * 100\n",
    "            val_loss /= len(valloader)\n",
    "            val_accuracy /= len(valloader)\n",
    "            val_f1_score /= len(valloader)\n",
    "            writer.add_scalar('Val_Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val_Accuracy', val_accuracy, epoch)\n",
    "            writer.add_scalar('Val_F1', val_f1_score, epoch)\n",
    "\n",
    "        print('Epoch {} - val loss:{}, accuracy:{}, f1_score:{}, time passed {}s'.format(epoch+1, val_loss, val_accuracy, val_f1_score, int(time.time()-starttime)))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "xtSpBheqICdj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test_evaluate(net, optimizer):\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0\n",
    "    val_f1_score = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    accuracy_func = Accuracy(num_classes=43, average='weighted').to(device)\n",
    "    f1_score_func = F1Score(num_classes=43, average='weighted').to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += accuracy_func(pred, labels) * 100\n",
    "            val_f1_score += f1_score_func(pred, labels) * 100\n",
    "        val_loss /= len(testloader)\n",
    "        val_accuracy /= len(testloader)\n",
    "        val_f1_score /= len(testloader)\n",
    "    print('Test evaluate - test loss:{}, accuracy:{}, f1_score:{}'.format(val_loss, val_accuracy, val_f1_score))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lx3C4-hLICdk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 4.1: Model performance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "W8Mi0kjGICdl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train loss:3.755649102877264, accuracy:3.699019432067871, f1_score:0.733150064945221, time passed 94s\n",
      "Epoch 1 - val loss:3.7543559414999828, accuracy:4.767628192901611, f1_score:0.9181628823280334, time passed 108s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [14], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(startmodel\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[0;32m      3\u001B[0m writer \u001B[38;5;241m=\u001B[39m SummaryWriter(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mruns/BaseModel\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mtrain_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstartmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [12], line 11\u001B[0m, in \u001B[0;36mtrain_evaluate\u001B[1;34m(net, optimizer, writer)\u001B[0m\n\u001B[0;32m      9\u001B[0m f1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     10\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m trainloader:\n\u001B[0;32m     12\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     13\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Innopolis\\_my\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1027\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1032\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1034\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mD:\\_MainProgs\\Python\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\_MainProgs\\Python\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\_MainProgs\\Python\\lib\\multiprocessing\\context.py:336\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\_MainProgs\\Python\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\_MainProgs\\Python\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# model without improving\n",
    "optimizer = torch.optim.SGD(startmodel.parameters(), lr=learning_rate)\n",
    "writer = SummaryWriter('runs/BaseModel')\n",
    "train_evaluate(startmodel, optimizer, writer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfSGPq6JICdl",
    "outputId": "b056d7c3-a181-4817-f7d4-f1751ced061f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_evaluate(startmodel, optimizer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1oPpHzzICdl",
    "outputId": "37ab43c7-eb9b-4179-95ae-5a401e5ba205"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - train loss:3.781892097159608, accuracy:3.792418956756592, f1_score:2.8831706047058105, time passed 12s\n",
      "Epoch 1 - val loss:3.6823583216894242, accuracy:5.6146979331970215, f1_score:4.456240653991699, time passed 15s\n",
      "Epoch 2 - train loss:3.5763260893625755, accuracy:8.048431396484375, f1_score:6.536133289337158, time passed 29s\n",
      "Epoch 2 - val loss:3.4965174198150635, accuracy:10.785829544067383, f1_score:8.527152061462402, time passed 30s\n",
      "Epoch 3 - train loss:3.404180214829641, accuracy:13.2968168258667, f1_score:10.187032699584961, time passed 39s\n",
      "Epoch 3 - val loss:3.3257961046128046, accuracy:15.344551086425781, f1_score:11.281533241271973, time passed 40s\n",
      "Epoch 4 - train loss:3.239979758654555, accuracy:17.996479034423828, f1_score:13.35980224609375, time passed 49s\n",
      "Epoch 4 - val loss:3.172314167022705, accuracy:20.20089340209961, f1_score:15.209571838378906, time passed 50s\n",
      "Epoch 5 - train loss:3.0986668100095773, accuracy:21.61085319519043, f1_score:16.096433639526367, time passed 59s\n",
      "Epoch 5 - val loss:3.0536800793239047, accuracy:21.462913513183594, f1_score:16.148221969604492, time passed 61s\n",
      "Epoch 6 - train loss:2.9663021711454, accuracy:25.101669311523438, f1_score:19.387361526489258, time passed 71s\n",
      "Epoch 6 - val loss:2.92787310055324, accuracy:25.423534393310547, f1_score:19.574487686157227, time passed 72s\n",
      "Epoch 7 - train loss:2.851425476270179, accuracy:27.37974739074707, f1_score:21.449478149414062, time passed 81s\n",
      "Epoch 7 - val loss:2.8305089133126393, accuracy:27.332305908203125, f1_score:21.428646087646484, time passed 82s\n",
      "Epoch 8 - train loss:2.7530210720349664, accuracy:29.256498336791992, f1_score:23.27709197998047, time passed 91s\n",
      "Epoch 8 - val loss:2.7325595787593295, accuracy:30.505952835083008, f1_score:24.584514617919922, time passed 92s\n",
      "Epoch 9 - train loss:2.6644895158401907, accuracy:31.51219940185547, f1_score:25.560543060302734, time passed 101s\n",
      "Epoch 9 - val loss:2.639714343207223, accuracy:31.584821701049805, f1_score:25.245506286621094, time passed 103s\n",
      "Epoch 10 - train loss:2.575680295081988, accuracy:33.5577507019043, f1_score:27.436843872070312, time passed 112s\n",
      "Epoch 10 - val loss:2.566342149462019, accuracy:33.31044006347656, f1_score:27.131906509399414, time passed 114s\n",
      "Epoch 11 - train loss:2.4959145114846426, accuracy:35.130950927734375, f1_score:28.732036590576172, time passed 124s\n",
      "Epoch 11 - val loss:2.5008489858536493, accuracy:34.163230895996094, f1_score:27.879661560058594, time passed 125s\n",
      "Epoch 12 - train loss:2.4232015952672046, accuracy:37.06024169921875, f1_score:30.841909408569336, time passed 134s\n",
      "Epoch 12 - val loss:2.4222018945784796, accuracy:36.13495635986328, f1_score:30.03789520263672, time passed 135s\n",
      "Epoch 13 - train loss:2.3546397457384085, accuracy:37.794307708740234, f1_score:31.636831283569336, time passed 144s\n",
      "Epoch 13 - val loss:2.3589597656613304, accuracy:37.76327896118164, f1_score:31.7895450592041, time passed 146s\n",
      "Epoch 14 - train loss:2.292430867071021, accuracy:39.70656967163086, f1_score:33.5976676940918, time passed 155s\n",
      "Epoch 14 - val loss:2.295680977049328, accuracy:38.66758346557617, f1_score:32.70500564575195, time passed 156s\n",
      "Epoch 15 - train loss:2.22782321253868, accuracy:40.39344787597656, f1_score:34.4172248840332, time passed 166s\n",
      "Epoch 15 - val loss:2.2265986715044295, accuracy:41.394805908203125, f1_score:35.05612564086914, time passed 167s\n",
      "Epoch 16 - train loss:2.1668274157667815, accuracy:42.15734100341797, f1_score:36.250789642333984, time passed 176s\n",
      "Epoch 16 - val loss:2.1719493695667813, accuracy:41.33470916748047, f1_score:35.59722900390625, time passed 178s\n",
      "Epoch 17 - train loss:2.11365037993209, accuracy:43.288352966308594, f1_score:37.33254623413086, time passed 187s\n",
      "Epoch 17 - val loss:2.1211999484470914, accuracy:43.017398834228516, f1_score:37.43991470336914, time passed 188s\n",
      "Epoch 18 - train loss:2.06293444682474, accuracy:44.581356048583984, f1_score:38.7949333190918, time passed 197s\n",
      "Epoch 18 - val loss:2.0728875682467507, accuracy:44.296592712402344, f1_score:38.620208740234375, time passed 198s\n",
      "Epoch 19 - train loss:2.0176747139186073, accuracy:45.320281982421875, f1_score:39.62211990356445, time passed 207s\n",
      "Epoch 19 - val loss:2.0168167522975375, accuracy:45.34397888183594, f1_score:39.85383224487305, time passed 209s\n",
      "Epoch 20 - train loss:1.971087877064535, accuracy:46.46394348144531, f1_score:40.88051986694336, time passed 218s\n",
      "Epoch 20 - val loss:1.9848771946770805, accuracy:46.11664581298828, f1_score:40.24854278564453, time passed 220s\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(improvedmodel.parameters(), lr=learning_rate)\n",
    "writer2 = SummaryWriter('runs/ImprovedModel')\n",
    "train_evaluate(improvedmodel, optimizer, writer2)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eh-iqszEICdm",
    "outputId": "65c10d15-c3c6-4f68-e311-d91be72a5e68"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test evaluate - test loss:1.9524168217623676, accuracy:46.34391784667969, f1_score:41.11750411987305\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(improvedmodel, optimizer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8Ryzm1jICdm",
    "outputId": "3b6ff343-d5c8-4943-f34c-46ab1b562677"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task2.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Kcr9BZHpICdm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 3.2: Machine learning or Deep learning model defining, training and hyper-parameters turning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "l1QeotcsICdm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NBUxzgjaICdn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 16, 16]             648\n",
      "       BatchNorm2d-2           [-1, 24, 16, 16]              48\n",
      "              ReLU-3           [-1, 24, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 24, 8, 8]               0\n",
      "            Conv2d-5             [-1, 24, 4, 4]             216\n",
      "       BatchNorm2d-6             [-1, 24, 4, 4]              48\n",
      "            Conv2d-7            [-1, 122, 4, 4]           2,928\n",
      "       BatchNorm2d-8            [-1, 122, 4, 4]             244\n",
      "              ReLU-9            [-1, 122, 4, 4]               0\n",
      "           Conv2d-10            [-1, 122, 8, 8]           2,928\n",
      "      BatchNorm2d-11            [-1, 122, 8, 8]             244\n",
      "             ReLU-12            [-1, 122, 8, 8]               0\n",
      "           Conv2d-13            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-14            [-1, 122, 4, 4]             244\n",
      "           Conv2d-15            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-16            [-1, 122, 4, 4]             244\n",
      "             ReLU-17            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-18            [-1, 244, 4, 4]               0\n",
      "           Conv2d-19            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-20            [-1, 122, 4, 4]             244\n",
      "             ReLU-21            [-1, 122, 4, 4]               0\n",
      "           Conv2d-22            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-23            [-1, 122, 4, 4]             244\n",
      "           Conv2d-24            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-25            [-1, 122, 4, 4]             244\n",
      "             ReLU-26            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-27            [-1, 244, 4, 4]               0\n",
      "           Conv2d-28            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-29            [-1, 122, 4, 4]             244\n",
      "             ReLU-30            [-1, 122, 4, 4]               0\n",
      "           Conv2d-31            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-32            [-1, 122, 4, 4]             244\n",
      "           Conv2d-33            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-34            [-1, 122, 4, 4]             244\n",
      "             ReLU-35            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-36            [-1, 244, 4, 4]               0\n",
      "           Conv2d-37            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-38            [-1, 122, 4, 4]             244\n",
      "             ReLU-39            [-1, 122, 4, 4]               0\n",
      "           Conv2d-40            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-41            [-1, 122, 4, 4]             244\n",
      "           Conv2d-42            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-43            [-1, 122, 4, 4]             244\n",
      "             ReLU-44            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-45            [-1, 244, 4, 4]               0\n",
      "           Conv2d-46            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-47            [-1, 244, 2, 2]             488\n",
      "           Conv2d-48            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-49            [-1, 244, 2, 2]             488\n",
      "             ReLU-50            [-1, 244, 2, 2]               0\n",
      "           Conv2d-51            [-1, 244, 4, 4]          59,536\n",
      "      BatchNorm2d-52            [-1, 244, 4, 4]             488\n",
      "             ReLU-53            [-1, 244, 4, 4]               0\n",
      "           Conv2d-54            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-55            [-1, 244, 2, 2]             488\n",
      "           Conv2d-56            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-57            [-1, 244, 2, 2]             488\n",
      "             ReLU-58            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-59            [-1, 488, 2, 2]               0\n",
      "           Conv2d-60            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-61            [-1, 244, 2, 2]             488\n",
      "             ReLU-62            [-1, 244, 2, 2]               0\n",
      "           Conv2d-63            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-64            [-1, 244, 2, 2]             488\n",
      "           Conv2d-65            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-66            [-1, 244, 2, 2]             488\n",
      "             ReLU-67            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-68            [-1, 488, 2, 2]               0\n",
      "           Conv2d-69            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-70            [-1, 244, 2, 2]             488\n",
      "             ReLU-71            [-1, 244, 2, 2]               0\n",
      "           Conv2d-72            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-73            [-1, 244, 2, 2]             488\n",
      "           Conv2d-74            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-75            [-1, 244, 2, 2]             488\n",
      "             ReLU-76            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-77            [-1, 488, 2, 2]               0\n",
      "           Conv2d-78            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-79            [-1, 244, 2, 2]             488\n",
      "             ReLU-80            [-1, 244, 2, 2]               0\n",
      "           Conv2d-81            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-82            [-1, 244, 2, 2]             488\n",
      "           Conv2d-83            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-84            [-1, 244, 2, 2]             488\n",
      "             ReLU-85            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-86            [-1, 488, 2, 2]               0\n",
      "           Conv2d-87            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-88            [-1, 244, 2, 2]             488\n",
      "             ReLU-89            [-1, 244, 2, 2]               0\n",
      "           Conv2d-90            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-91            [-1, 244, 2, 2]             488\n",
      "           Conv2d-92            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-93            [-1, 244, 2, 2]             488\n",
      "             ReLU-94            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-95            [-1, 488, 2, 2]               0\n",
      "           Conv2d-96            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-97            [-1, 244, 2, 2]             488\n",
      "             ReLU-98            [-1, 244, 2, 2]               0\n",
      "           Conv2d-99            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-100            [-1, 244, 2, 2]             488\n",
      "          Conv2d-101            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-102            [-1, 244, 2, 2]             488\n",
      "            ReLU-103            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-104            [-1, 488, 2, 2]               0\n",
      "          Conv2d-105            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-106            [-1, 244, 2, 2]             488\n",
      "            ReLU-107            [-1, 244, 2, 2]               0\n",
      "          Conv2d-108            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-109            [-1, 244, 2, 2]             488\n",
      "          Conv2d-110            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-111            [-1, 244, 2, 2]             488\n",
      "            ReLU-112            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-113            [-1, 488, 2, 2]               0\n",
      "          Conv2d-114            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-115            [-1, 244, 2, 2]             488\n",
      "            ReLU-116            [-1, 244, 2, 2]               0\n",
      "          Conv2d-117            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-118            [-1, 244, 2, 2]             488\n",
      "          Conv2d-119            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-120            [-1, 244, 2, 2]             488\n",
      "            ReLU-121            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-122            [-1, 488, 2, 2]               0\n",
      "          Conv2d-123            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-124            [-1, 488, 1, 1]             976\n",
      "          Conv2d-125            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-126            [-1, 488, 1, 1]             976\n",
      "            ReLU-127            [-1, 488, 1, 1]               0\n",
      "          Conv2d-128            [-1, 488, 2, 2]         238,144\n",
      "     BatchNorm2d-129            [-1, 488, 2, 2]             976\n",
      "            ReLU-130            [-1, 488, 2, 2]               0\n",
      "          Conv2d-131            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-132            [-1, 488, 1, 1]             976\n",
      "          Conv2d-133            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-134            [-1, 488, 1, 1]             976\n",
      "            ReLU-135            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-136            [-1, 976, 1, 1]               0\n",
      "          Conv2d-137            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-138            [-1, 488, 1, 1]             976\n",
      "            ReLU-139            [-1, 488, 1, 1]               0\n",
      "          Conv2d-140            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-141            [-1, 488, 1, 1]             976\n",
      "          Conv2d-142            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-143            [-1, 488, 1, 1]             976\n",
      "            ReLU-144            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-145            [-1, 976, 1, 1]               0\n",
      "          Conv2d-146            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-147            [-1, 488, 1, 1]             976\n",
      "            ReLU-148            [-1, 488, 1, 1]               0\n",
      "          Conv2d-149            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-150            [-1, 488, 1, 1]             976\n",
      "          Conv2d-151            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-152            [-1, 488, 1, 1]             976\n",
      "            ReLU-153            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-154            [-1, 976, 1, 1]               0\n",
      "          Conv2d-155            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-156            [-1, 488, 1, 1]             976\n",
      "            ReLU-157            [-1, 488, 1, 1]               0\n",
      "          Conv2d-158            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-159            [-1, 488, 1, 1]             976\n",
      "          Conv2d-160            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-161            [-1, 488, 1, 1]             976\n",
      "            ReLU-162            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-163            [-1, 976, 1, 1]               0\n",
      "          Conv2d-164           [-1, 2048, 1, 1]       1,998,848\n",
      "     BatchNorm2d-165           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-166           [-1, 2048, 1, 1]               0\n",
      "          Linear-167                   [-1, 43]          88,107\n",
      "    ShuffleNetV2-168                   [-1, 43]               0\n",
      "================================================================\n",
      "Total params: 5,433,103\n",
      "Trainable params: 5,433,103\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.88\n",
      "Params size (MB): 20.73\n",
      "Estimated Total Size (MB): 22.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = models.shufflenet_v2_x2_0()\n",
    "        self.net.trainable = False # Freeze the layers of the pretrained model\n",
    "        self.net.fc = nn.Linear(2048, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "shuff = Net().to(device)\n",
    "summary(shuff, (3, 32, 32))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OM4i-9lpICdn",
    "outputId": "1a76a514-12b6-4aa1-ce4c-3a660c061075"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 16, 16]             648\n",
      "       BatchNorm2d-2           [-1, 24, 16, 16]              48\n",
      "              ReLU-3           [-1, 24, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 24, 8, 8]               0\n",
      "            Conv2d-5             [-1, 24, 4, 4]             216\n",
      "       BatchNorm2d-6             [-1, 24, 4, 4]              48\n",
      "            Conv2d-7            [-1, 122, 4, 4]           2,928\n",
      "       BatchNorm2d-8            [-1, 122, 4, 4]             244\n",
      "              ReLU-9            [-1, 122, 4, 4]               0\n",
      "           Conv2d-10            [-1, 122, 8, 8]           2,928\n",
      "      BatchNorm2d-11            [-1, 122, 8, 8]             244\n",
      "             ReLU-12            [-1, 122, 8, 8]               0\n",
      "           Conv2d-13            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-14            [-1, 122, 4, 4]             244\n",
      "           Conv2d-15            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-16            [-1, 122, 4, 4]             244\n",
      "             ReLU-17            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-18            [-1, 244, 4, 4]               0\n",
      "           Conv2d-19            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-20            [-1, 122, 4, 4]             244\n",
      "             ReLU-21            [-1, 122, 4, 4]               0\n",
      "           Conv2d-22            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-23            [-1, 122, 4, 4]             244\n",
      "           Conv2d-24            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-25            [-1, 122, 4, 4]             244\n",
      "             ReLU-26            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-27            [-1, 244, 4, 4]               0\n",
      "           Conv2d-28            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-29            [-1, 122, 4, 4]             244\n",
      "             ReLU-30            [-1, 122, 4, 4]               0\n",
      "           Conv2d-31            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-32            [-1, 122, 4, 4]             244\n",
      "           Conv2d-33            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-34            [-1, 122, 4, 4]             244\n",
      "             ReLU-35            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-36            [-1, 244, 4, 4]               0\n",
      "           Conv2d-37            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-38            [-1, 122, 4, 4]             244\n",
      "             ReLU-39            [-1, 122, 4, 4]               0\n",
      "           Conv2d-40            [-1, 122, 4, 4]           1,098\n",
      "      BatchNorm2d-41            [-1, 122, 4, 4]             244\n",
      "           Conv2d-42            [-1, 122, 4, 4]          14,884\n",
      "      BatchNorm2d-43            [-1, 122, 4, 4]             244\n",
      "             ReLU-44            [-1, 122, 4, 4]               0\n",
      " InvertedResidual-45            [-1, 244, 4, 4]               0\n",
      "           Conv2d-46            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-47            [-1, 244, 2, 2]             488\n",
      "           Conv2d-48            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-49            [-1, 244, 2, 2]             488\n",
      "             ReLU-50            [-1, 244, 2, 2]               0\n",
      "           Conv2d-51            [-1, 244, 4, 4]          59,536\n",
      "      BatchNorm2d-52            [-1, 244, 4, 4]             488\n",
      "             ReLU-53            [-1, 244, 4, 4]               0\n",
      "           Conv2d-54            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-55            [-1, 244, 2, 2]             488\n",
      "           Conv2d-56            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-57            [-1, 244, 2, 2]             488\n",
      "             ReLU-58            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-59            [-1, 488, 2, 2]               0\n",
      "           Conv2d-60            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-61            [-1, 244, 2, 2]             488\n",
      "             ReLU-62            [-1, 244, 2, 2]               0\n",
      "           Conv2d-63            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-64            [-1, 244, 2, 2]             488\n",
      "           Conv2d-65            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-66            [-1, 244, 2, 2]             488\n",
      "             ReLU-67            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-68            [-1, 488, 2, 2]               0\n",
      "           Conv2d-69            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-70            [-1, 244, 2, 2]             488\n",
      "             ReLU-71            [-1, 244, 2, 2]               0\n",
      "           Conv2d-72            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-73            [-1, 244, 2, 2]             488\n",
      "           Conv2d-74            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-75            [-1, 244, 2, 2]             488\n",
      "             ReLU-76            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-77            [-1, 488, 2, 2]               0\n",
      "           Conv2d-78            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-79            [-1, 244, 2, 2]             488\n",
      "             ReLU-80            [-1, 244, 2, 2]               0\n",
      "           Conv2d-81            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-82            [-1, 244, 2, 2]             488\n",
      "           Conv2d-83            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-84            [-1, 244, 2, 2]             488\n",
      "             ReLU-85            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-86            [-1, 488, 2, 2]               0\n",
      "           Conv2d-87            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-88            [-1, 244, 2, 2]             488\n",
      "             ReLU-89            [-1, 244, 2, 2]               0\n",
      "           Conv2d-90            [-1, 244, 2, 2]           2,196\n",
      "      BatchNorm2d-91            [-1, 244, 2, 2]             488\n",
      "           Conv2d-92            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-93            [-1, 244, 2, 2]             488\n",
      "             ReLU-94            [-1, 244, 2, 2]               0\n",
      " InvertedResidual-95            [-1, 488, 2, 2]               0\n",
      "           Conv2d-96            [-1, 244, 2, 2]          59,536\n",
      "      BatchNorm2d-97            [-1, 244, 2, 2]             488\n",
      "             ReLU-98            [-1, 244, 2, 2]               0\n",
      "           Conv2d-99            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-100            [-1, 244, 2, 2]             488\n",
      "          Conv2d-101            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-102            [-1, 244, 2, 2]             488\n",
      "            ReLU-103            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-104            [-1, 488, 2, 2]               0\n",
      "          Conv2d-105            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-106            [-1, 244, 2, 2]             488\n",
      "            ReLU-107            [-1, 244, 2, 2]               0\n",
      "          Conv2d-108            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-109            [-1, 244, 2, 2]             488\n",
      "          Conv2d-110            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-111            [-1, 244, 2, 2]             488\n",
      "            ReLU-112            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-113            [-1, 488, 2, 2]               0\n",
      "          Conv2d-114            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-115            [-1, 244, 2, 2]             488\n",
      "            ReLU-116            [-1, 244, 2, 2]               0\n",
      "          Conv2d-117            [-1, 244, 2, 2]           2,196\n",
      "     BatchNorm2d-118            [-1, 244, 2, 2]             488\n",
      "          Conv2d-119            [-1, 244, 2, 2]          59,536\n",
      "     BatchNorm2d-120            [-1, 244, 2, 2]             488\n",
      "            ReLU-121            [-1, 244, 2, 2]               0\n",
      "InvertedResidual-122            [-1, 488, 2, 2]               0\n",
      "          Conv2d-123            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-124            [-1, 488, 1, 1]             976\n",
      "          Conv2d-125            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-126            [-1, 488, 1, 1]             976\n",
      "            ReLU-127            [-1, 488, 1, 1]               0\n",
      "          Conv2d-128            [-1, 488, 2, 2]         238,144\n",
      "     BatchNorm2d-129            [-1, 488, 2, 2]             976\n",
      "            ReLU-130            [-1, 488, 2, 2]               0\n",
      "          Conv2d-131            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-132            [-1, 488, 1, 1]             976\n",
      "          Conv2d-133            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-134            [-1, 488, 1, 1]             976\n",
      "            ReLU-135            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-136            [-1, 976, 1, 1]               0\n",
      "          Conv2d-137            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-138            [-1, 488, 1, 1]             976\n",
      "            ReLU-139            [-1, 488, 1, 1]               0\n",
      "          Conv2d-140            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-141            [-1, 488, 1, 1]             976\n",
      "          Conv2d-142            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-143            [-1, 488, 1, 1]             976\n",
      "            ReLU-144            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-145            [-1, 976, 1, 1]               0\n",
      "          Conv2d-146            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-147            [-1, 488, 1, 1]             976\n",
      "            ReLU-148            [-1, 488, 1, 1]               0\n",
      "          Conv2d-149            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-150            [-1, 488, 1, 1]             976\n",
      "          Conv2d-151            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-152            [-1, 488, 1, 1]             976\n",
      "            ReLU-153            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-154            [-1, 976, 1, 1]               0\n",
      "          Conv2d-155            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-156            [-1, 488, 1, 1]             976\n",
      "            ReLU-157            [-1, 488, 1, 1]               0\n",
      "          Conv2d-158            [-1, 488, 1, 1]           4,392\n",
      "     BatchNorm2d-159            [-1, 488, 1, 1]             976\n",
      "          Conv2d-160            [-1, 488, 1, 1]         238,144\n",
      "     BatchNorm2d-161            [-1, 488, 1, 1]             976\n",
      "            ReLU-162            [-1, 488, 1, 1]               0\n",
      "InvertedResidual-163            [-1, 976, 1, 1]               0\n",
      "        Identity-164            [-1, 976, 1, 1]               0\n",
      "          Linear-165                   [-1, 43]          42,011\n",
      "    ShuffleNetV2-166                   [-1, 43]               0\n",
      "================================================================\n",
      "Total params: 3,384,063\n",
      "Trainable params: 3,384,063\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.84\n",
      "Params size (MB): 12.91\n",
      "Estimated Total Size (MB): 14.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class NetReduced(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetReduced, self).__init__()\n",
    "        self.net = models.shufflenet_v2_x2_0()\n",
    "        self.net.trainable = False # Freeze the layers of the pretrained model\n",
    "        self.net.conv5 = Identity()\n",
    "        self.net.fc = nn.Linear(976, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "shuffreduced = NetReduced().to(device)\n",
    "summary(shuffreduced, (3, 32, 32))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZbvqHoxICdn",
    "outputId": "bf70e52b-44ad-4eca-8d56-65d81cbd375e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 4.2: Model performance evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ctu9ib0bICdo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - train loss:3.648371103691728, accuracy:4.753658294677734, f1_score:3.287752389907837, time passed 11s\n",
      "Epoch 1 - val loss:3.5586927504766557, accuracy:5.920902252197266, f1_score:4.342501640319824, time passed 12s\n",
      "Epoch 2 - train loss:3.5260258276168615, accuracy:6.133736610412598, f1_score:4.1751484870910645, time passed 24s\n",
      "Epoch 2 - val loss:3.5192053885686967, accuracy:6.1612868309021, f1_score:4.159658432006836, time passed 25s\n",
      "Epoch 3 - train loss:3.487732232433476, accuracy:7.4097137451171875, f1_score:5.223920822143555, time passed 37s\n",
      "Epoch 3 - val loss:3.475822437377203, accuracy:8.52220630645752, f1_score:5.894680500030518, time passed 39s\n",
      "Epoch 4 - train loss:3.442376007772472, accuracy:9.0651273727417, f1_score:6.445792198181152, time passed 50s\n",
      "Epoch 4 - val loss:3.447174060912359, accuracy:8.774038314819336, f1_score:6.170717716217041, time passed 52s\n",
      "Epoch 5 - train loss:3.405845971956645, accuracy:10.460771560668945, f1_score:7.56613302230835, time passed 63s\n",
      "Epoch 5 - val loss:3.415984244573684, accuracy:10.433836936950684, f1_score:7.6884541511535645, time passed 65s\n",
      "Epoch 6 - train loss:3.3514991525101334, accuracy:12.414870262145996, f1_score:9.0331392288208, time passed 76s\n",
      "Epoch 6 - val loss:3.3598494983854748, accuracy:12.64022445678711, f1_score:9.190140724182129, time passed 77s\n",
      "Epoch 7 - train loss:3.2741112921335924, accuracy:15.531599044799805, f1_score:11.300756454467773, time passed 90s\n",
      "Epoch 7 - val loss:3.2692232586088634, accuracy:16.188758850097656, f1_score:12.06800651550293, time passed 91s\n",
      "Epoch 8 - train loss:3.172417789289396, accuracy:17.866107940673828, f1_score:13.195487976074219, time passed 102s\n",
      "Epoch 8 - val loss:3.1496772311982655, accuracy:18.672733306884766, f1_score:13.977951049804688, time passed 104s\n",
      "Epoch 9 - train loss:3.035865816351486, accuracy:21.690147399902344, f1_score:16.61731719970703, time passed 115s\n",
      "Epoch 9 - val loss:3.010518028622582, accuracy:21.191049575805664, f1_score:16.456052780151367, time passed 117s\n",
      "Epoch 10 - train loss:2.8863982795036, accuracy:25.18582534790039, f1_score:20.02899742126465, time passed 128s\n",
      "Epoch 10 - val loss:2.8778965586707708, accuracy:24.710966110229492, f1_score:19.681110382080078, time passed 130s\n",
      "Epoch 11 - train loss:2.751121695727518, accuracy:27.564115524291992, f1_score:22.403581619262695, time passed 142s\n",
      "Epoch 11 - val loss:2.7443664982205345, accuracy:26.888736724853516, f1_score:21.839885711669922, time passed 143s\n",
      "Epoch 12 - train loss:2.605697458737517, accuracy:31.029150009155273, f1_score:25.865509033203125, time passed 155s\n",
      "Epoch 12 - val loss:2.6146095480237688, accuracy:29.404190063476562, f1_score:24.217763900756836, time passed 156s\n",
      "Epoch 13 - train loss:2.473874722441582, accuracy:33.360252380371094, f1_score:28.062734603881836, time passed 168s\n",
      "Epoch 13 - val loss:2.489504541669573, accuracy:31.484661102294922, f1_score:26.361356735229492, time passed 169s\n",
      "Epoch 14 - train loss:2.332714322495134, accuracy:36.61027145385742, f1_score:31.164627075195312, time passed 181s\n",
      "Epoch 14 - val loss:2.3762608596256802, accuracy:35.57406234741211, f1_score:30.114139556884766, time passed 183s\n",
      "Epoch 15 - train loss:2.200442752609514, accuracy:39.672515869140625, f1_score:34.20123291015625, time passed 194s\n",
      "Epoch 15 - val loss:2.2667777878897533, accuracy:37.29109573364258, f1_score:31.943336486816406, time passed 196s\n",
      "Epoch 16 - train loss:2.0828197059566027, accuracy:42.886051177978516, f1_score:37.486000061035156, time passed 208s\n",
      "Epoch 16 - val loss:2.1715760231018066, accuracy:37.80620574951172, f1_score:32.70146560668945, time passed 209s\n",
      "Epoch 17 - train loss:1.9710721691993818, accuracy:44.97246551513672, f1_score:39.58366775512695, time passed 221s\n",
      "Epoch 17 - val loss:2.0903386842636835, accuracy:39.82658004760742, f1_score:35.06423568725586, time passed 222s\n",
      "Epoch 18 - train loss:1.8634835057062646, accuracy:47.956878662109375, f1_score:42.69806671142578, time passed 235s\n",
      "Epoch 18 - val loss:2.001074575242542, accuracy:41.94711685180664, f1_score:37.37565231323242, time passed 236s\n",
      "Epoch 19 - train loss:1.7707171742230245, accuracy:50.63190460205078, f1_score:45.371456146240234, time passed 247s\n",
      "Epoch 19 - val loss:1.9232714005878992, accuracy:44.40247344970703, f1_score:40.369380950927734, time passed 249s\n",
      "Epoch 20 - train loss:1.6766366101291081, accuracy:53.1926155090332, f1_score:48.128177642822266, time passed 260s\n",
      "Epoch 20 - val loss:1.8747325795037406, accuracy:45.43269348144531, f1_score:41.12009811401367, time passed 262s\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(shuff.parameters(),lr=learning_rate)\n",
    "writer3 = SummaryWriter('runs/TLmodel')\n",
    "train_evaluate(shuff, optimizer, writer3)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbhMK_eYICdo",
    "outputId": "73e89677-1855-4bde-9648-7cf05f7a2e85"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test evaluate - test loss:1.8525429323867515, accuracy:45.261905670166016, f1_score:41.258541107177734\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(shuff, optimizer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujC2ZlRUICdo",
    "outputId": "a9a02180-3cd6-464c-d097-b9dbd460d87b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 - train loss:3.6911758037462628, accuracy:4.6996612548828125, f1_score:3.239332675933838, time passed 11s\n",
      "Epoch 1 - val loss:3.613515853881836, accuracy:6.227106094360352, f1_score:3.969083547592163, time passed 13s\n",
      "Epoch 2 - train loss:3.560694186654809, accuracy:6.94125509262085, f1_score:4.685476303100586, time passed 24s\n",
      "Epoch 2 - val loss:3.543572948092506, accuracy:7.17719841003418, f1_score:5.064234733581543, time passed 26s\n",
      "Epoch 3 - train loss:3.4979838786059863, accuracy:7.9467620849609375, f1_score:5.433537006378174, time passed 37s\n",
      "Epoch 3 - val loss:3.492972044717698, accuracy:7.789606094360352, f1_score:5.187887191772461, time passed 39s\n",
      "Epoch 4 - train loss:3.442298067759161, accuracy:9.542827606201172, f1_score:6.5686726570129395, time passed 50s\n",
      "Epoch 4 - val loss:3.4473774546668645, accuracy:10.073260307312012, f1_score:6.948268413543701, time passed 51s\n",
      "Epoch 5 - train loss:3.3917610400343596, accuracy:11.340286254882812, f1_score:7.742509365081787, time passed 64s\n",
      "Epoch 5 - val loss:3.3962382134937106, accuracy:11.7931547164917, f1_score:8.049946784973145, time passed 65s\n",
      "Epoch 6 - train loss:3.3301006686197567, accuracy:13.653389930725098, f1_score:9.507869720458984, time passed 77s\n",
      "Epoch 6 - val loss:3.3265040942600796, accuracy:13.793498039245605, f1_score:9.37266731262207, time passed 78s\n",
      "Epoch 7 - train loss:3.248016755874843, accuracy:15.747587203979492, f1_score:11.258232116699219, time passed 89s\n",
      "Epoch 7 - val loss:3.248280479794457, accuracy:15.790979385375977, f1_score:11.033042907714844, time passed 91s\n",
      "Epoch 8 - train loss:3.1552913303244603, accuracy:19.12651824951172, f1_score:13.891132354736328, time passed 102s\n",
      "Epoch 8 - val loss:3.1616739999680292, accuracy:19.00755500793457, f1_score:13.716988563537598, time passed 103s\n",
      "Epoch 9 - train loss:3.0485726203003973, accuracy:22.355133056640625, f1_score:16.769975662231445, time passed 116s\n",
      "Epoch 9 - val loss:3.0457636628832137, accuracy:20.787546157836914, f1_score:15.442355155944824, time passed 117s\n",
      "Epoch 10 - train loss:2.9293558662884855, accuracy:25.434406280517578, f1_score:19.574304580688477, time passed 129s\n",
      "Epoch 10 - val loss:2.9280708517347063, accuracy:24.673765182495117, f1_score:19.085765838623047, time passed 130s\n",
      "Epoch 11 - train loss:2.7959750319180423, accuracy:28.381364822387695, f1_score:22.343229293823242, time passed 142s\n",
      "Epoch 11 - val loss:2.827569745835804, accuracy:26.551054000854492, f1_score:20.5419979095459, time passed 144s\n",
      "Epoch 12 - train loss:2.6560034066030425, accuracy:31.523876190185547, f1_score:25.399555206298828, time passed 155s\n",
      "Epoch 12 - val loss:2.691961265745617, accuracy:29.524383544921875, f1_score:23.507535934448242, time passed 157s\n",
      "Epoch 13 - train loss:2.524152256038091, accuracy:34.72135925292969, f1_score:28.557186126708984, time passed 169s\n",
      "Epoch 13 - val loss:2.5956315994262695, accuracy:30.740612030029297, f1_score:25.14284896850586, time passed 170s\n",
      "Epoch 14 - train loss:2.405082936156286, accuracy:37.47275924682617, f1_score:31.38617706298828, time passed 182s\n",
      "Epoch 14 - val loss:2.5017371291206, accuracy:32.738094329833984, f1_score:27.09438705444336, time passed 183s\n",
      "Epoch 15 - train loss:2.2950389728154224, accuracy:39.52511978149414, f1_score:33.42212677001953, time passed 194s\n",
      "Epoch 15 - val loss:2.422355583735875, accuracy:33.9171257019043, f1_score:28.561355590820312, time passed 196s\n",
      "Epoch 16 - train loss:2.1990495471105183, accuracy:41.607643127441406, f1_score:35.6326904296875, time passed 207s\n",
      "Epoch 16 - val loss:2.3318742343357632, accuracy:36.544185638427734, f1_score:31.050729751586914, time passed 209s\n",
      "Epoch 17 - train loss:2.0960479844106388, accuracy:44.01219940185547, f1_score:38.34492111206055, time passed 221s\n",
      "Epoch 17 - val loss:2.2459411053430465, accuracy:37.91495132446289, f1_score:32.09077835083008, time passed 223s\n",
      "Epoch 18 - train loss:2.0059104602630824, accuracy:46.344764709472656, f1_score:40.676876068115234, time passed 234s\n",
      "Epoch 18 - val loss:2.191111207008362, accuracy:39.0167121887207, f1_score:33.7304801940918, time passed 235s\n",
      "Epoch 19 - train loss:1.9212113773986086, accuracy:48.063899993896484, f1_score:42.52327346801758, time passed 246s\n",
      "Epoch 19 - val loss:2.1293820653642928, accuracy:40.224361419677734, f1_score:34.79924011230469, time passed 248s\n",
      "Epoch 20 - train loss:1.842541711787655, accuracy:50.250038146972656, f1_score:44.823280334472656, time passed 260s\n",
      "Epoch 20 - val loss:2.054670969645182, accuracy:41.283199310302734, f1_score:36.26681137084961, time passed 262s\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(shuffreduced.parameters(),lr=learning_rate)\n",
    "writer4 = SummaryWriter('runs/TLmodelReduced')\n",
    "train_evaluate(shuffreduced, optimizer, writer4)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojgXhQ8uICdp",
    "outputId": "ad9396f5-e630-42a4-b2b8-261ccb6485f1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test evaluate - test loss:2.034531048050633, accuracy:42.806880950927734, f1_score:38.17628479003906\n"
     ]
    }
   ],
   "source": [
    "test_evaluate(shuffreduced, optimizer)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6XCXlIXICdp",
    "outputId": "59c8c8a2-ce81-4356-faf7-df19a6ae9b60"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 5: Conclusion and possible improvements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "9TbdQuwtICdp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2.1\n",
    "The goal is to improve model efficiency using minimum of three techniques presented in the course.\n",
    "\n",
    "To do this, Dropout2d, BatchNorm2d and ReLU layers was used.\n",
    "\n",
    "As a result, accuracy was significantly increased from 9% to 46% based on test dataset.\n",
    "\n",
    "### Task 2.2\n",
    "The goal is to reduce pretrained model parameters without loosing accuracy of more than 5%.\n",
    "\n",
    "shufflenet_v2_x2_0 was chosen as pretrained model. Shufflenet for 43 classes have 5,433,103 parameters. For reduced version of Shufflenet last conv5 layer was replaced by custom identity layer.\n",
    "\n",
    "As a result, number of parameters was reduced from 5,433,103 to 3,384,063 which is 37.7% lower, but accuracy was reduced from 45.2% to 42.8% which is 2.4% lower. This means that model is now can be evaluated much faster than model without reducing and a lot of accuracy has not been lost for this.\n",
    "\n",
    "The presented models can be improved by increasing the number of learning epochs and changing the structure of the neural networks.\n",
    "The performance metrics can be seen below.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-d5bc94ca102ab4e2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d5bc94ca102ab4e2\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}